---
title: "Tuning Cluster Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tuning_and_metrics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Setup

**Important:** Make sure to install the developer version of `parsnip` to access
all current functionality of `tidyclust`:

```{r, eval = FALSE}
remotes::install_github("tidymodels/parsnip")
```

Load libraries:

```{r setup}
library(tidyclust)
library(tidyverse)
library(parsnip)
library(tidymodels)
```

```{r setup_secret, echo = FALSE}
library(ggforce)
set.seed(838383)
```

Load and clean a dataset:

```{r}
data("penguins", package = "modeldata")

penguins <- penguins %>%
  select(bill_length_mm, bill_depth_mm) %>%
  drop_na()
```

## Tuning in unsupervised settings

In *supervised modeling* scenarios, we observe values of a target (or "response")
variable, and we measure the success of our model based on how well it predicts
future response values.  To select hyperparameter values, we **tune** them, trying
many possible values and measuring how well each performs when predicting
target values of test data.

In the *unsupervised modeling* setting of `tidyclust`, there is no such objective
measure of success.  Clustering analyses are typically exploratory rather than
testable.  Nonetheless, the core tuning principle of varying inputs and quantifying
results is still applicable.


## Specify and fit a model

In this example, we will fit a $k$-means cluster model to the `palmerpenguins`
dataset, using only the bill length and bill depth of penguins as predictors.

(Please refer to the k-means vignette for an in-depth discussion of this model
specification.)

Our goal will be to select an appropriate number of clusters for the model 
based on metrics.

First, we set up cross-validation samples for our data:

```{r}
pen_cv <- vfold_cv(penguins)
```

Next, we specify our model with a tuning parameter, make a workflow,
and establish a range of possible values of `num_clusters` to try:

```{r}
kmeans_spec <- k_means(num_clusters = tune()) 

pens_rec <- recipe(~., data = penguins)

kmeans_wflow <- workflow(pens_rec, kmeans_spec)

clust_num_grid <- grid_regular(num_clusters(), 
                               levels = 10)
  
clust_num_grid

```

Then, we can use `tune_cluster()` to compute metrics on each cross-validation
split, for each possible choice of number of clusters.

```{r}
res <- tune_cluster(
  kmenas_wflow,
  resamples = pens_cv,
  grid = clust_num_grid,
  control = control_grid(save_pred = TRUE, extract = identity),
  metrics = cluster_metric_set(tot_wss, tot_sse)
) 
```



#### Comparison to auxilary variables

```{r, eval=FALSE}
penguins <- penguins %>%
  drop_na(bill_length_mm, bill_depth_mm) 

penguins %>%
  cbind(extract_cluster_assignment(kmeans_fit)) %>%
  enrichment(.cluster, species)
```

## Choosing the number of clusters

Traditional "elbow" plot:
