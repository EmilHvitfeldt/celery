[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement codeofconduct@rstudio.com. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 tidyclust authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/hier_clust.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Hierarchical Clustering","text":"Important: Make sure install developer version parsnip workflows access current functionality tidyclust: Load libraries: Load clean dataset: yet read k_means vignette, recommend reading first; functions used vignette explained detail .","code":"remotes::install_github(\"tidymodels/parsnip\") remotes::install_github(\"tidymodels/workflows@celery\") library(workflows) library(parsnip) library(tidyclust) #>  #> Attaching package: 'tidyclust' #> The following object is masked from 'package:parsnip': #>  #>     prepare_data library(tidyverse) #> ── Attaching packages #> ─────────────────────────────────────── #> tidyverse 1.3.2 ── #> ✔ ggplot2 3.3.6      ✔ purrr   0.3.4  #> ✔ tibble  3.1.8      ✔ dplyr   1.0.10 #> ✔ tidyr   1.2.1      ✔ stringr 1.4.1  #> ✔ readr   2.1.2      ✔ forcats 0.5.2  #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() library(tidymodels) #> ── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ── #> ✔ broom        1.0.1     ✔ rsample      1.1.0 #> ✔ dials        1.0.0     ✔ tune         1.0.0 #> ✔ infer        1.0.3     ✔ workflowsets 1.0.0 #> ✔ modeldata    1.0.1     ✔ yardstick    1.1.0 #> ✔ recipes      1.0.1      #> ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ── #> ✖ scales::discard()         masks purrr::discard() #> ✖ dplyr::filter()           masks stats::filter() #> ✖ recipes::fixed()          masks stringr::fixed() #> ✖ dplyr::lag()              masks stats::lag() #> ✖ tidyclust::prepare_data() masks parsnip::prepare_data() #> ✖ yardstick::spec()         masks readr::spec() #> ✖ recipes::step()           masks stats::step() #> • Use suppressPackageStartupMessages() to eliminate package startup messages data(\"penguins\", package = \"modeldata\")  penguins <- penguins %>%   select(bill_length_mm, bill_depth_mm) %>%   drop_na()     # shuffle rows penguins <- penguins %>%   sample_n(nrow(penguins))"},{"path":"/articles/hier_clust.html","id":"a-brief-introduction-to-hierarchical-clustering","dir":"Articles","previous_headings":"","what":"A brief introduction to hierarchical clustering","title":"Hierarchical Clustering","text":"Hierarchical Clustering, sometimes called Agglomerative Clustering, method unsupervised learning produces dendrogram, can used partition observations clusters. hierarchical clustering process begins observation ’s cluster; .e., n clusters n observations.  closest two observations joined together single cluster.  process continues, closest two clusters joined (“aggolermated”) step.  result process dendrogram, shows joining clusters tree form:","code":"#> Warning in dist(fake_dat): NAs introduced by coercion #> Warning in dist(fake_dat): NAs introduced by coercion"},{"path":"/articles/hier_clust.html","id":"clusters-from-dendrogram","dir":"Articles","previous_headings":"A brief introduction to hierarchical clustering","what":"Clusters from dendrogram","title":"Hierarchical Clustering","text":"produce partition-style cluster assignment dendrogram, one must “cut” tree chosen height:  observations remain joined dendrogram cut height considered cluster together:","code":"#> # A tibble: 5 × 2 #>   observation cluster_assignment #>   <chr>                    <int> #> 1 a                            1 #> 2 b                            2 #> 3 c                            2 #> 4 d                            3 #> 5 e                            3"},{"path":"/articles/hier_clust.html","id":"methods-of-aggolmeration","dir":"Articles","previous_headings":"A brief introduction to hierarchical clustering","what":"Methods of aggolmeration","title":"Hierarchical Clustering","text":"every step agglomeration, measure distances current clusters. cluster containing (possibly) multiple points, mean measure distance? four common approaches cluster-cluster distancing, aka “linkage”: single linkage: distance two clusters distance two closest observations. average linkage: distance two clusters average distances observations one cluster observations . complete linkage: distance two clusters distance two furthest observations. centroid method: distance two clusters distance centroids (geometric mean median). Ward’s method: distance two clusters proportional increase error sum squares (ESS) result joining . ESS computed sum squared distances observations cluster, centroid cluster. also worth mentioning McQuitty method, retains information previously joined clusters measure future linkage distance. method currently supported model fitting, prediction, tidyclust.","code":""},{"path":"/articles/hier_clust.html","id":"hier_clust-specification-in-tidyclust","dir":"Articles","previous_headings":"","what":"hier_clust specification in {tidyclust}","title":"Hierarchical Clustering","text":"specify hierarchical clustering model tidyclust, simply choose value num_clusters (optionally) linkage method: Currently, supported engine stats::hclust(). default linkage","code":"hc_spec <- hier_clust(num_clusters = 3,                        linkage_method = \"average\")   hc_spec #> Hierarchical Clustering Specification (partition) #>  #> Main Arguments: #>   num_clusters = 3 #>   linkage_method = average #>  #> Computational engine: stats"},{"path":"/articles/hier_clust.html","id":"fitting-hier_clust-models","dir":"Articles","previous_headings":"","what":"Fitting hier_clust models","title":"Hierarchical Clustering","text":"fit model data usual way: produce dendrogram plot, access engine fit: (Although see , dendrograms often informative moderate large size datasets.)  can also extract standard tidyclust summary list: Note , although hierarchical clustering algorithm focused cluster centroids way \\(k\\)-means , still able compute geometric mean predictors cluster:","code":"hc_fit <- hc_spec %>%   fit(~ bill_length_mm + bill_depth_mm,        data = penguins)  hc_fit %>%    summary() #>         Length Class      Mode #> spec    4      hier_clust list #> fit     7      hclust     list #> elapsed 1      -none-     list #> preproc 4      -none-     list hc_fit$fit %>% plot() hc_summary <- hc_fit %>% extract_fit_summary()   hc_summary %>% str() #> List of 7 #>  $ cluster_names      : Factor w/ 3 levels \"Cluster_1\",\"Cluster_2\",..: 1 2 3 #>  $ centroids          : tibble [3 × 2] (S3: tbl_df/tbl/data.frame) #>   ..$ bill_length_mm: num [1:3] 38.8 47.9 56.6 #>   ..$ bill_depth_mm : num [1:3] 18.3 16.2 16.7 #>  $ n_members          : 'table' int [1:3(1d)] 153 184 5 #>  $ within_sse         : num [1:3] 378.4 573.9 9.7 #>  $ tot_sse            : num 1803 #>  $ orig_labels        : NULL #>  $ cluster_assignments: Factor w/ 3 levels \"Cluster_1\",\"Cluster_2\",..: 1 1 1 2 2 2 2 2 1 2 ... hc_fit %>% extract_centroids() #> # A tibble: 3 × 3 #>   .cluster  bill_length_mm bill_depth_mm #>   <fct>              <dbl>         <dbl> #> 1 Cluster_1           38.8          18.3 #> 2 Cluster_2           47.9          16.2 #> 3 Cluster_3           56.6          16.7"},{"path":"/articles/hier_clust.html","id":"prediction","dir":"Articles","previous_headings":"","what":"Prediction","title":"Hierarchical Clustering","text":"predict cluster assignment new observation, find closest cluster. measure “closeness” dependent specified type linkage model: single linkage: new observation assigned cluster nearest observation training data. complete linkage: new observation assigned cluster smallest maximum distances training observations new observation. average linkage: new observation assigned cluster smallest average distances training observations new observation. centroid method: new observation assigned cluster closest centroid, prediction k_means. Ward’s method: new observation assigned cluster smallest increase error sum squares (ESS) due new addition. ESS computed sum squared distances observations cluster, centroid cluster. ’s important note guarantee predict() training data produce results extract_cluster_assignments(). process clusters created aggolmerations results particular partition; training observation treated new data, predicted manner truly new information.","code":"hc_preds <- hc_fit %>% predict(penguins)  hc_preds #> # A tibble: 342 × 1 #>    .pred_cluster #>    <fct>         #>  1 Cluster_1     #>  2 Cluster_1     #>  3 Cluster_1     #>  4 Cluster_2     #>  5 Cluster_3     #>  6 Cluster_3     #>  7 Cluster_2     #>  8 Cluster_2     #>  9 Cluster_1     #> 10 Cluster_2     #> # … with 332 more rows cbind(   hc_preds,   extract_cluster_assignment(hc_fit) ) #>     .pred_cluster  .cluster #> 1       Cluster_1 Cluster_1 #> 2       Cluster_1 Cluster_1 #> 3       Cluster_1 Cluster_1 #> 4       Cluster_2 Cluster_2 #> 5       Cluster_3 Cluster_2 #> 6       Cluster_3 Cluster_2 #> 7       Cluster_2 Cluster_2 #> 8       Cluster_2 Cluster_2 #> 9       Cluster_1 Cluster_1 #> 10      Cluster_2 Cluster_2 #> 11      Cluster_2 Cluster_2 #> 12      Cluster_1 Cluster_1 #> 13      Cluster_1 Cluster_1 #> 14      Cluster_1 Cluster_1 #> 15      Cluster_2 Cluster_2 #> 16      Cluster_1 Cluster_1 #> 17      Cluster_2 Cluster_2 #> 18      Cluster_2 Cluster_2 #> 19      Cluster_2 Cluster_2 #> 20      Cluster_1 Cluster_1 #> 21      Cluster_1 Cluster_1 #> 22      Cluster_1 Cluster_1 #> 23      Cluster_2 Cluster_2 #> 24      Cluster_1 Cluster_1 #> 25      Cluster_2 Cluster_2 #> 26      Cluster_2 Cluster_2 #> 27      Cluster_2 Cluster_2 #> 28      Cluster_2 Cluster_2 #> 29      Cluster_2 Cluster_2 #> 30      Cluster_2 Cluster_2 #> 31      Cluster_1 Cluster_1 #> 32      Cluster_2 Cluster_2 #> 33      Cluster_2 Cluster_2 #> 34      Cluster_2 Cluster_2 #> 35      Cluster_2 Cluster_2 #> 36      Cluster_3 Cluster_2 #> 37      Cluster_2 Cluster_2 #> 38      Cluster_1 Cluster_1 #> 39      Cluster_2 Cluster_2 #> 40      Cluster_2 Cluster_2 #> 41      Cluster_2 Cluster_2 #> 42      Cluster_2 Cluster_2 #> 43      Cluster_2 Cluster_2 #> 44      Cluster_2 Cluster_2 #> 45      Cluster_2 Cluster_2 #> 46      Cluster_2 Cluster_2 #> 47      Cluster_1 Cluster_1 #> 48      Cluster_1 Cluster_1 #> 49      Cluster_1 Cluster_1 #> 50      Cluster_2 Cluster_2 #> 51      Cluster_1 Cluster_1 #> 52      Cluster_1 Cluster_1 #> 53      Cluster_2 Cluster_2 #> 54      Cluster_1 Cluster_1 #> 55      Cluster_2 Cluster_2 #> 56      Cluster_2 Cluster_2 #> 57      Cluster_2 Cluster_2 #> 58      Cluster_1 Cluster_1 #> 59      Cluster_1 Cluster_1 #> 60      Cluster_1 Cluster_1 #> 61      Cluster_2 Cluster_2 #> 62      Cluster_2 Cluster_2 #> 63      Cluster_1 Cluster_1 #> 64      Cluster_2 Cluster_2 #> 65      Cluster_3 Cluster_3 #> 66      Cluster_1 Cluster_1 #> 67      Cluster_1 Cluster_1 #> 68      Cluster_1 Cluster_1 #> 69      Cluster_2 Cluster_2 #> 70      Cluster_2 Cluster_2 #> 71      Cluster_1 Cluster_1 #> 72      Cluster_1 Cluster_1 #> 73      Cluster_1 Cluster_1 #> 74      Cluster_1 Cluster_1 #> 75      Cluster_3 Cluster_2 #> 76      Cluster_2 Cluster_2 #> 77      Cluster_2 Cluster_2 #> 78      Cluster_1 Cluster_1 #> 79      Cluster_2 Cluster_2 #> 80      Cluster_1 Cluster_1 #> 81      Cluster_1 Cluster_1 #> 82      Cluster_1 Cluster_1 #> 83      Cluster_1 Cluster_1 #> 84      Cluster_2 Cluster_2 #> 85      Cluster_2 Cluster_2 #> 86      Cluster_2 Cluster_2 #> 87      Cluster_1 Cluster_1 #> 88      Cluster_2 Cluster_2 #> 89      Cluster_2 Cluster_2 #> 90      Cluster_1 Cluster_1 #> 91      Cluster_1 Cluster_1 #> 92      Cluster_2 Cluster_2 #> 93      Cluster_1 Cluster_1 #> 94      Cluster_2 Cluster_2 #> 95      Cluster_2 Cluster_2 #> 96      Cluster_1 Cluster_1 #> 97      Cluster_1 Cluster_1 #> 98      Cluster_2 Cluster_2 #> 99      Cluster_2 Cluster_2 #> 100     Cluster_1 Cluster_2 #> 101     Cluster_2 Cluster_2 #> 102     Cluster_2 Cluster_2 #> 103     Cluster_1 Cluster_1 #> 104     Cluster_1 Cluster_1 #> 105     Cluster_2 Cluster_2 #> 106     Cluster_1 Cluster_1 #> 107     Cluster_1 Cluster_1 #> 108     Cluster_2 Cluster_2 #> 109     Cluster_1 Cluster_1 #> 110     Cluster_2 Cluster_2 #> 111     Cluster_1 Cluster_1 #> 112     Cluster_1 Cluster_1 #> 113     Cluster_1 Cluster_1 #> 114     Cluster_1 Cluster_1 #> 115     Cluster_2 Cluster_2 #> 116     Cluster_2 Cluster_2 #> 117     Cluster_2 Cluster_2 #> 118     Cluster_2 Cluster_2 #> 119     Cluster_2 Cluster_2 #> 120     Cluster_2 Cluster_2 #> 121     Cluster_1 Cluster_1 #> 122     Cluster_1 Cluster_1 #> 123     Cluster_1 Cluster_1 #> 124     Cluster_1 Cluster_1 #> 125     Cluster_2 Cluster_2 #> 126     Cluster_2 Cluster_2 #> 127     Cluster_1 Cluster_1 #> 128     Cluster_1 Cluster_1 #> 129     Cluster_2 Cluster_2 #> 130     Cluster_1 Cluster_1 #> 131     Cluster_2 Cluster_2 #> 132     Cluster_1 Cluster_1 #> 133     Cluster_1 Cluster_1 #> 134     Cluster_3 Cluster_2 #> 135     Cluster_1 Cluster_1 #> 136     Cluster_2 Cluster_2 #> 137     Cluster_3 Cluster_2 #> 138     Cluster_2 Cluster_2 #> 139     Cluster_1 Cluster_1 #> 140     Cluster_1 Cluster_1 #> 141     Cluster_2 Cluster_2 #> 142     Cluster_2 Cluster_2 #> 143     Cluster_2 Cluster_2 #> 144     Cluster_2 Cluster_1 #> 145     Cluster_2 Cluster_2 #> 146     Cluster_2 Cluster_2 #> 147     Cluster_2 Cluster_2 #> 148     Cluster_2 Cluster_2 #> 149     Cluster_1 Cluster_1 #> 150     Cluster_2 Cluster_2 #> 151     Cluster_2 Cluster_2 #> 152     Cluster_1 Cluster_1 #> 153     Cluster_2 Cluster_2 #> 154     Cluster_2 Cluster_2 #> 155     Cluster_3 Cluster_2 #> 156     Cluster_1 Cluster_1 #> 157     Cluster_2 Cluster_2 #> 158     Cluster_2 Cluster_2 #> 159     Cluster_1 Cluster_1 #> 160     Cluster_2 Cluster_2 #> 161     Cluster_1 Cluster_1 #> 162     Cluster_2 Cluster_2 #> 163     Cluster_1 Cluster_1 #> 164     Cluster_1 Cluster_1 #> 165     Cluster_2 Cluster_2 #> 166     Cluster_2 Cluster_2 #> 167     Cluster_2 Cluster_2 #> 168     Cluster_2 Cluster_2 #> 169     Cluster_1 Cluster_1 #> 170     Cluster_2 Cluster_2 #> 171     Cluster_1 Cluster_1 #> 172     Cluster_1 Cluster_2 #> 173     Cluster_1 Cluster_1 #> 174     Cluster_1 Cluster_1 #> 175     Cluster_1 Cluster_1 #> 176     Cluster_2 Cluster_2 #> 177     Cluster_3 Cluster_2 #> 178     Cluster_3 Cluster_2 #> 179     Cluster_1 Cluster_1 #> 180     Cluster_2 Cluster_2 #> 181     Cluster_1 Cluster_1 #> 182     Cluster_1 Cluster_1 #> 183     Cluster_2 Cluster_2 #> 184     Cluster_2 Cluster_2 #> 185     Cluster_1 Cluster_1 #> 186     Cluster_2 Cluster_2 #> 187     Cluster_1 Cluster_1 #> 188     Cluster_1 Cluster_1 #> 189     Cluster_2 Cluster_2 #> 190     Cluster_1 Cluster_1 #> 191     Cluster_2 Cluster_2 #> 192     Cluster_2 Cluster_2 #> 193     Cluster_3 Cluster_3 #> 194     Cluster_1 Cluster_1 #> 195     Cluster_1 Cluster_1 #> 196     Cluster_2 Cluster_2 #> 197     Cluster_1 Cluster_1 #> 198     Cluster_1 Cluster_1 #> 199     Cluster_2 Cluster_2 #> 200     Cluster_2 Cluster_2 #> 201     Cluster_1 Cluster_1 #> 202     Cluster_2 Cluster_2 #> 203     Cluster_2 Cluster_2 #> 204     Cluster_1 Cluster_1 #> 205     Cluster_1 Cluster_1 #> 206     Cluster_1 Cluster_1 #> 207     Cluster_1 Cluster_1 #> 208     Cluster_2 Cluster_2 #> 209     Cluster_2 Cluster_2 #> 210     Cluster_2 Cluster_2 #> 211     Cluster_1 Cluster_1 #> 212     Cluster_1 Cluster_1 #> 213     Cluster_1 Cluster_1 #> 214     Cluster_2 Cluster_2 #> 215     Cluster_1 Cluster_1 #> 216     Cluster_2 Cluster_2 #> 217     Cluster_2 Cluster_2 #> 218     Cluster_1 Cluster_1 #> 219     Cluster_1 Cluster_1 #> 220     Cluster_1 Cluster_1 #> 221     Cluster_3 Cluster_2 #> 222     Cluster_2 Cluster_2 #> 223     Cluster_1 Cluster_1 #> 224     Cluster_1 Cluster_1 #> 225     Cluster_2 Cluster_2 #> 226     Cluster_1 Cluster_1 #> 227     Cluster_1 Cluster_1 #> 228     Cluster_2 Cluster_2 #> 229     Cluster_2 Cluster_2 #> 230     Cluster_1 Cluster_1 #> 231     Cluster_1 Cluster_1 #> 232     Cluster_2 Cluster_2 #> 233     Cluster_2 Cluster_2 #> 234     Cluster_1 Cluster_1 #> 235     Cluster_1 Cluster_1 #> 236     Cluster_2 Cluster_2 #> 237     Cluster_1 Cluster_1 #> 238     Cluster_1 Cluster_1 #> 239     Cluster_2 Cluster_2 #> 240     Cluster_3 Cluster_3 #> 241     Cluster_1 Cluster_1 #> 242     Cluster_1 Cluster_2 #> 243     Cluster_1 Cluster_1 #> 244     Cluster_2 Cluster_2 #> 245     Cluster_2 Cluster_2 #> 246     Cluster_2 Cluster_2 #> 247     Cluster_2 Cluster_2 #> 248     Cluster_1 Cluster_1 #> 249     Cluster_1 Cluster_1 #> 250     Cluster_2 Cluster_2 #> 251     Cluster_1 Cluster_1 #> 252     Cluster_1 Cluster_1 #> 253     Cluster_1 Cluster_1 #> 254     Cluster_2 Cluster_2 #> 255     Cluster_1 Cluster_1 #> 256     Cluster_2 Cluster_2 #> 257     Cluster_2 Cluster_2 #> 258     Cluster_2 Cluster_2 #> 259     Cluster_1 Cluster_1 #> 260     Cluster_2 Cluster_2 #> 261     Cluster_2 Cluster_2 #> 262     Cluster_2 Cluster_2 #> 263     Cluster_1 Cluster_1 #> 264     Cluster_1 Cluster_1 #> 265     Cluster_2 Cluster_2 #> 266     Cluster_3 Cluster_2 #> 267     Cluster_2 Cluster_2 #> 268     Cluster_2 Cluster_2 #> 269     Cluster_1 Cluster_1 #> 270     Cluster_1 Cluster_1 #> 271     Cluster_2 Cluster_2 #> 272     Cluster_1 Cluster_1 #> 273     Cluster_1 Cluster_1 #> 274     Cluster_1 Cluster_1 #> 275     Cluster_1 Cluster_1 #> 276     Cluster_1 Cluster_1 #> 277     Cluster_2 Cluster_2 #> 278     Cluster_1 Cluster_1 #> 279     Cluster_1 Cluster_1 #> 280     Cluster_2 Cluster_2 #> 281     Cluster_3 Cluster_3 #> 282     Cluster_2 Cluster_2 #> 283     Cluster_2 Cluster_2 #> 284     Cluster_1 Cluster_1 #> 285     Cluster_2 Cluster_2 #> 286     Cluster_1 Cluster_1 #> 287     Cluster_1 Cluster_1 #> 288     Cluster_1 Cluster_1 #> 289     Cluster_2 Cluster_2 #> 290     Cluster_1 Cluster_1 #> 291     Cluster_2 Cluster_2 #> 292     Cluster_1 Cluster_1 #> 293     Cluster_1 Cluster_1 #> 294     Cluster_2 Cluster_2 #> 295     Cluster_2 Cluster_2 #> 296     Cluster_2 Cluster_2 #> 297     Cluster_2 Cluster_2 #> 298     Cluster_3 Cluster_2 #> 299     Cluster_2 Cluster_2 #> 300     Cluster_1 Cluster_1 #> 301     Cluster_2 Cluster_2 #> 302     Cluster_1 Cluster_1 #> 303     Cluster_1 Cluster_1 #> 304     Cluster_1 Cluster_1 #> 305     Cluster_2 Cluster_2 #> 306     Cluster_1 Cluster_1 #> 307     Cluster_1 Cluster_2 #> 308     Cluster_2 Cluster_2 #> 309     Cluster_2 Cluster_2 #> 310     Cluster_1 Cluster_1 #> 311     Cluster_3 Cluster_2 #> 312     Cluster_2 Cluster_2 #> 313     Cluster_2 Cluster_2 #> 314     Cluster_2 Cluster_2 #> 315     Cluster_1 Cluster_1 #> 316     Cluster_1 Cluster_1 #> 317     Cluster_2 Cluster_2 #> 318     Cluster_2 Cluster_2 #> 319     Cluster_1 Cluster_1 #> 320     Cluster_2 Cluster_2 #> 321     Cluster_2 Cluster_2 #> 322     Cluster_2 Cluster_2 #> 323     Cluster_2 Cluster_2 #> 324     Cluster_1 Cluster_1 #> 325     Cluster_2 Cluster_2 #> 326     Cluster_2 Cluster_2 #> 327     Cluster_2 Cluster_2 #> 328     Cluster_2 Cluster_2 #> 329     Cluster_2 Cluster_2 #> 330     Cluster_1 Cluster_1 #> 331     Cluster_3 Cluster_3 #> 332     Cluster_1 Cluster_1 #> 333     Cluster_2 Cluster_2 #> 334     Cluster_1 Cluster_1 #> 335     Cluster_2 Cluster_2 #> 336     Cluster_2 Cluster_2 #> 337     Cluster_2 Cluster_2 #> 338     Cluster_1 Cluster_1 #> 339     Cluster_2 Cluster_2 #> 340     Cluster_1 Cluster_1 #> 341     Cluster_1 Cluster_1 #> 342     Cluster_1 Cluster_1"},{"path":"/articles/hier_clust.html","id":"reconciling-partitions","dir":"Articles","previous_headings":"","what":"Reconciling partitions","title":"Hierarchical Clustering","text":"Suppose produced cluster assignments two models: hierarchical clustering model three clusters () \\(k\\)-means clustering model five clusters (). can combine assignments? notice three-cluster assignments hier_clust line perfectly five-cluster assignments k_means. However, fully unrelated assignments. example, KM_2 \\(k\\)-means assignment fell inside HC_1 hierarchical assignments. goal relabel five \\(k\\)-means clusters match three cluster names hierarchical output. can accomplished reconcile_clusterings(). function expects input two vectors cluster labels. first labels matches, second labels recoded first. trying simply match names across two -size clusterings, option one_to_one must set FALSE. example, can see KM_1, KM_2, KM_5 matched HC_1; KM_3 KM_4 matched HC_2. Notice clusters KM set matched HC_3; evidently, small cluster manifest clearly \\(k\\)-means clustering.","code":"km_spec <- k_means(num_clusters = 5) km_fit <- km_spec %>%   fit(~., data = penguins)  km_preds <- predict(km_fit, penguins, prefix = \"KM_\") hc_preds <- predict(hc_fit, penguins, prefix = \"HC_\") tibble(   hc = hc_preds$.pred_cluster,   km = km_preds$.pred_cluster ) %>%    count(hc, km) #> # A tibble: 8 × 3 #>   hc    km        n #>   <fct> <fct> <int> #> 1 HC_1  KM_1     80 #> 2 HC_1  KM_2     72 #> 3 HC_1  KM_3      3 #> 4 HC_1  KM_5      1 #> 5 HC_2  KM_3     28 #> 6 HC_2  KM_4     64 #> 7 HC_2  KM_5     76 #> 8 HC_3  KM_4     18 reconcile_clusterings(primary_cluster_assignment = hc_preds$.pred_cluster,                        alt_cluster_assignment = km_preds$.pred_cluster,                       one_to_one = FALSE) #> # A tibble: 342 × 3 #>    primary alt   alt_recoded #>    <fct>   <fct> <chr>       #>  1 HC_1    KM_1  HC_1        #>  2 HC_1    KM_2  HC_1        #>  3 HC_1    KM_2  HC_1        #>  4 HC_2    KM_3  HC_2        #>  5 HC_3    KM_4  HC_2        #>  6 HC_3    KM_4  HC_2        #>  7 HC_2    KM_3  HC_2        #>  8 HC_2    KM_5  HC_2        #>  9 HC_1    KM_2  HC_1        #> 10 HC_2    KM_4  HC_2        #> # … with 332 more rows"},{"path":"/articles/k_means.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"k-means","text":"Important: Make sure install developer version parsnip workflows access current functionality tidyclust: Load libraries: Load clean dataset: end vignette, find brief overview k-means algorithm, well algorithmic variant details, like reference.","code":"remotes::install_github(\"tidymodels/parsnip\") remotes::install_github(\"tidymodels/workflows@celery\") library(workflows) library(parsnip) library(tidyclust) library(tidyverse) library(tidymodels) data(\"penguins\", package = \"modeldata\")  penguins <- penguins %>%   select(bill_length_mm, bill_depth_mm) %>%   drop_na()     # shuffle rows penguins <- penguins %>%   sample_n(nrow(penguins))"},{"path":"/articles/k_means.html","id":"k-means-specification-in-tidyclust","dir":"Articles","previous_headings":"","what":"k-means specification in {tidyclust}","title":"k-means","text":"specify k-means model tidyclust, simply choose value num_clusters: currently two engines: stats::kmeans (default) ClusterR::KMeans_rcpp. also possible change algorithmic details implementation, changing engine /using corresponding arguments engine functions: Note stats::kmeans ClusterR::KMeans_rcpp implementations different default settings algorithmic details, recommended deliberate explicit choosing options. (See end document detail algorithmic options defaults.)","code":"kmeans_spec <- k_means(num_clusters = 3)   kmeans_spec #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 3 #>  #> Computational engine: stats kmeans_spec_lloyd <- k_means(num_clusters = 3) %>%   parsnip::set_engine(\"stats\", algorithm = \"Lloyd\")  kmeans_spec_cr <- k_means(num_clusters = 3) %>%   parsnip::set_engine(\"ClusterR\", initializer = \"random\")"},{"path":"/articles/k_means.html","id":"fitting-k-means-models","dir":"Articles","previous_headings":"","what":"Fitting k-means models","title":"k-means","text":"specified, model may “fit” dataset providing formula data frame manner tidymodels model fit. Note unlike supervised modeling, formula include response variable. access results produced engine - case, stats::kmeans - simply extract fit fitted model object: tidyclust also provides function, extract_fit_summary(), produce list model summary information format consistent across cluster model specifications engines","code":"kmeans_fit <- kmeans_spec %>%   fit(~ bill_length_mm + bill_depth_mm,        data = penguins)  kmeans_fit %>%    summary() #>         Length Class   Mode #> spec    4      k_means list #> fit     9      kmeans  list #> elapsed 1      -none-  list #> preproc 4      -none-  list kmeans_fit$fit #> K-means clustering with 3 clusters of sizes 85, 141, 116 #>  #> Cluster means: #>   bill_length_mm bill_depth_mm #> 1       50.90353      17.33647 #> 2       38.40355      18.27943 #> 3       45.51379      15.64397 #>  #> Clustering vector: #>   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  #>   2   2   2   3   1   1   3   3   2   1   1   2   2   2   3   2   1   3   3   2  #>  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  #>   2   2   1   2   1   1   3   3   3   3   3   1   3   3   3   1   1   2   3   1  #>  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  #>   3   1   3   3   3   1   2   2   2   1   2   2   3   2   1   3   3   2   3   2  #>  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  #>   3   3   2   1   1   2   2   2   1   1   2   2   2   2   1   3   1   2   1   2  #>  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100  #>   2   2   2   1   1   3   2   3   1   2   2   3   2   3   1   2   2   3   3   3  #> 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  #>   3   3   2   2   3   2   2   3   2   3   2   2   2   3   1   3   3   1   3   3  #> 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140  #>   2   2   2   2   1   3   2   2   3   2   1   2   2   1   2   3   1   3   2   2  #> 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160  #>   3   3   1   3   3   3   1   1   2   1   3   2   3   1   1   2   1   3   2   3  #> 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180  #>   2   3   2   3   1   3   3   3   2   3   2   3   2   2   2   3   1   1   2   3  #> 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200  #>   2   2   3   3   2   3   2   2   3   2   3   1   1   2   2   1   2   2   3   3  #> 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220  #>   2   1   3   2   2   2   2   3   1   1   2   2   2   3   2   1   1   2   2   2  #> 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240  #>   1   1   2   2   3   2   2   3   1   2   2   3   1   2   2   1   2   2   3   1  #> 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260  #>   3   3   2   1   1   1   3   2   2   1   2   2   3   1   2   3   3   1   2   3  #> 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280  #>   1   1   3   2   1   1   3   3   2   2   3   2   2   2   2   2   3   2   2   1  #> 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300  #>   1   1   3   2   3   2   2   2   3   2   3   2   2   1   3   3   3   1   3   2  #> 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320  #>   1   2   2   2   1   2   3   3   3   2   1   3   1   1   3   2   3   3   2   1  #> 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340  #>   3   3   3   3   1   3   3   3   1   2   1   2   3   2   1   1   1   2   1   2  #> 341 342  #>   3   3  #>  #> Within cluster sum of squares by cluster: #> [1] 617.9859 944.4986 754.7437 #>  (between_SS / total_SS =  79.8 %) #>  #> Available components: #>  #> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" #> [6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\" kmeans_summary <- kmeans_fit %>%   extract_fit_summary()   kmeans_summary %>%str() #> List of 7 #>  $ cluster_names      : Factor w/ 3 levels \"Cluster_1\",\"Cluster_2\",..: 1 2 3 #>  $ centroids          : tibble [3 × 2] (S3: tbl_df/tbl/data.frame) #>   ..$ bill_length_mm: num [1:3] 45.5 50.9 38.4 #>   ..$ bill_depth_mm : num [1:3] 15.6 17.3 18.3 #>  $ n_members          : int [1:3] 116 85 141 #>  $ within_sse         : num [1:3] 755 618 944 #>  $ tot_sse            : num 11494 #>  $ orig_labels        : int [1:342] 2 2 2 3 1 1 3 3 2 1 ... #>  $ cluster_assignments: Factor w/ 3 levels \"Cluster_1\",\"Cluster_2\",..: 1 1 1 2 3 3 2 2 1 3 ..."},{"path":"/articles/k_means.html","id":"cluster-assignments-and-centers","dir":"Articles","previous_headings":"","what":"Cluster assignments and centers","title":"k-means","text":"primary objective fitting clustering model typically assign observations clusters. access , use extract_cluster_assignment() function: Note function renames clusters accordance standard tidyclust naming convention ordering: clusters named “Cluster_1”, “Cluster_2”, etc. numbered order appear rows training dataset. reconcile standardized cluster labels engine output, refer back full model fit summary: example, see cluster labelled “3” stats::kmeans engine function - label assigned randomly implementation - first appear training data, converted “Cluster_1” standardized labels.","code":"kmeans_fit %>%   extract_cluster_assignment() #> # A tibble: 342 × 1 #>    .cluster  #>    <fct>     #>  1 Cluster_1 #>  2 Cluster_1 #>  3 Cluster_1 #>  4 Cluster_2 #>  5 Cluster_3 #>  6 Cluster_3 #>  7 Cluster_2 #>  8 Cluster_2 #>  9 Cluster_1 #> 10 Cluster_3 #> # … with 332 more rows tibble(   orig_labels = kmeans_summary$orig_labels,   standard_labels = kmeans_summary$cluster_assignments ) #> # A tibble: 342 × 2 #>    orig_labels standard_labels #>          <int> <fct>           #>  1           2 Cluster_1       #>  2           2 Cluster_1       #>  3           2 Cluster_1       #>  4           3 Cluster_2       #>  5           1 Cluster_3       #>  6           1 Cluster_3       #>  7           3 Cluster_2       #>  8           3 Cluster_2       #>  9           2 Cluster_1       #> 10           1 Cluster_3       #> # … with 332 more rows"},{"path":"/articles/k_means.html","id":"centroids","dir":"Articles","previous_headings":"Cluster assignments and centers","what":"Centroids","title":"k-means","text":"secondary output interest often characterization clusters; .e., data feature trends cluster seem represent? commonly, clusters characterized mean values predictor space, .k.. centroids. can accessed full summary: can also accessed directly fitted model : Based output, might say Cluster_1 penguins smaller bill lengths, Cluster_2 smaller bill depths, Cluster_3 penguins large bills dimensions.","code":"kmeans_summary$centroids #> # A tibble: 3 × 2 #>   bill_length_mm bill_depth_mm #>            <dbl>         <dbl> #> 1           45.5          15.6 #> 2           50.9          17.3 #> 3           38.4          18.3 kmeans_fit %>%   extract_centroids() #> # A tibble: 3 × 3 #>   .cluster  bill_length_mm bill_depth_mm #>   <fct>              <dbl>         <dbl> #> 1 Cluster_1           45.5          15.6 #> 2 Cluster_2           50.9          17.3 #> 3 Cluster_3           38.4          18.3"},{"path":"/articles/k_means.html","id":"prediction","dir":"Articles","previous_headings":"","what":"Prediction","title":"k-means","text":"Since \\(k\\)-means algorithm ultimately assigns training observations cluster closest centroid, natural “predict” test observations also belong closest centroid cluster. predict() function behaves expected, producing cluster assignment predictions new data based distance fitted model centroids. attach predictions dataset column, use augment():","code":"new_penguin <- tibble(   bill_length_mm = 42,   bill_depth_mm = 17 )  kmeans_fit %>%   predict(new_penguin) #> # A tibble: 1 × 1 #>   .pred_cluster #>   <fct>         #> 1 Cluster_2 kmeans_fit %>%   augment(penguins) #> # A tibble: 342 × 3 #>    bill_length_mm bill_depth_mm .pred_cluster #>             <dbl>         <dbl> <fct>         #>  1           39.6          20.7 Cluster_1     #>  2           36.2          17.3 Cluster_1     #>  3           32.1          15.5 Cluster_1     #>  4           47.6          18.3 Cluster_2     #>  5           52            18.1 Cluster_3     #>  6           52.7          19.8 Cluster_3     #>  7           45.2          16.4 Cluster_2     #>  8           46.6          14.2 Cluster_2     #>  9           34.4          18.4 Cluster_1     #> 10           49.8          15.9 Cluster_3     #> # … with 332 more rows"},{"path":"/articles/k_means.html","id":"metrics","dir":"Articles","previous_headings":"","what":"Metrics","title":"k-means","text":"Since clustering unsupervised method, target/outcome variable, objective notion predictive success. However, many common approaches exist quantifying quality particular cluster partition structure.","code":""},{"path":"/articles/k_means.html","id":"sum-of-squared-error","dir":"Articles","previous_headings":"Metrics","what":"Sum of squared error","title":"k-means","text":"One simple metric within cluster sum--squared error (WSS), measures sum distances observations cluster center. sometimes scaled total sum--squared error (TSS), distance observations global centroid; particular, ratio WSS/TSS often computed. principle, small values WSS WSS/TSS ratio suggest observations within clusters closer (similar) clusters. WSS TSS come “free” model fit summary, can accessed directly model fit: can also see within sum--squares cluster, rather totalled, within_cluster_sse():","code":"kmeans_summary$within_sse #> [1] 754.7437 617.9859 944.4986 kmeans_summary$tot_sse #> [1] 11494.04  kmeans_fit %>% tot_wss() #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 tot_wss standard       2317. kmeans_fit %>% tot_sse() #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 tot_sse standard      11494.  kmeans_fit %>% sse_ratio() #> # A tibble: 1 × 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 sse_ratio standard       0.202 kmeans_fit %>%   within_cluster_sse() #> # A tibble: 3 × 3 #>   .cluster    wss n_members #>   <fct>     <dbl>     <int> #> 1 Cluster_1  755.       116 #> 2 Cluster_2  618.        85 #> 3 Cluster_3  944.       141"},{"path":"/articles/k_means.html","id":"silhouette","dir":"Articles","previous_headings":"Metrics","what":"Silhouette","title":"k-means","text":"Another common measure cluster structure called silhouette. silhouette single observation proportional average distance observation within-cluster observations minus average distance outside-cluster observations; normalized greater two average. principle, large silhouette (close 1) suggests observation similar within cluster outside cluster. can average silhouettes get metric full clustering fit. Beause computation silhouette depends original observation values, dataset must also supplied function.","code":"kmeans_fit %>%   avg_silhouette(penguins) #> # A tibble: 1 × 3 #>   .metric        .estimator .estimate #>   <chr>          <chr>          <dbl> #> 1 avg_silhouette standard       0.488"},{"path":"/articles/k_means.html","id":"changing-distance-measures","dir":"Articles","previous_headings":"Metrics","what":"Changing distance measures","title":"k-means","text":"metrics depend measuring distance points /centroids. default, ordinary Euclidean distance used. However, possible select different distance function. sum squares metrics, distance function supplied must take two arguments (.e., observation locations centroid locations). sihouette metric, distance function must find pairwise distances single matrix (.e., pairwise distances observations). using metrics cluster model selection, see Tuning vignette.","code":"my_dist_1 <- function(x) {   Rfast::Dist(x, method = \"manhattan\") }  my_dist_2 <- function(x, y) {   Rfast::dista(x, y, method = \"manhattan\") }  kmeans_fit %>% sse_ratio(dist_fun = my_dist_2) #> # A tibble: 1 × 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 sse_ratio standard       0.202  kmeans_fit %>% avg_silhouette(penguins, dist_fun = my_dist_1) #> # A tibble: 1 × 3 #>   .metric        .estimator .estimate #>   <chr>          <chr>          <dbl> #> 1 avg_silhouette standard       0.494"},{"path":"/articles/k_means.html","id":"workflows","dir":"Articles","previous_headings":"","what":"Workflows","title":"k-means","text":"workflow structure tidymodels also usable tidyclust objects. following example, try two recipes clustering penguins bill dimensions. second recipe, log-scale predictors clustering.","code":"penguins_recipe_1 <- recipe(~ bill_length_mm + bill_depth_mm,                             data = penguins)  penguins_recipe_2 <- recipe(~ bill_length_mm + bill_depth_mm,                             data = penguins) %>%   step_log(all_numeric_predictors())  wflow_1 <- workflow() %>%   add_model(kmeans_spec) %>%   add_recipe(penguins_recipe_1)  wflow_2 <- workflow() %>%   add_model(kmeans_spec) %>%   add_recipe(penguins_recipe_2)  wflow_1 %>%   fit(penguins) %>%   extract_centroids() #> # A tibble: 3 × 3 #>   .cluster  bill_length_mm bill_depth_mm #>   <fct>              <dbl>         <dbl> #> 1 Cluster_1           38.4          18.3 #> 2 Cluster_2           45.5          15.6 #> 3 Cluster_3           50.9          17.3  wflow_2 %>%   fit(penguins) %>%   extract_centroids() #> # A tibble: 3 × 3 #>   .cluster  bill_length_mm bill_depth_mm #>   <fct>              <dbl>         <dbl> #> 1 Cluster_1           3.65          2.90 #> 2 Cluster_2           3.90          2.92 #> 3 Cluster_3           3.85          2.70"},{"path":"/articles/k_means.html","id":"a-brief-introduction-to-the-k-means-algorithm","dir":"Articles","previous_headings":"","what":"A brief introduction to the k-means algorithm","title":"k-means","text":"k-means method unsupervised learning produces partitioning observations k unique clusters. goal k-means minimize sum squared Euclidian distances observations cluster centroid, geometric mean, cluster. k-means clustering, observed variables (columns) considered locations axes multidimensional space. example, plot , point represents observation one penguin, location 2-dimensional space determined bill length bill depth penguin.  k-means cluster assignment achieved iterating convergence random initial conditions. algorithm typically proceeds follows: Choose k random observations dataset. locations space declared initial centroids.  Assign observation nearest centroid.  Compute new centroids cluster.  Repeat steps 2 3 centroids change.","code":""},{"path":"/articles/k_means.html","id":"iteration-of-centroids","dir":"Articles","previous_headings":"A brief introduction to the k-means algorithm","what":"Iteration of centroids","title":"k-means","text":"also variation implementations update process takes place. example, shown common implementation known Lloyd Forgy method. update steps : Assign observations closest centroid. Recalculate centroids. Repeat convergence. One variant approach MacQueen method, updates centroids continually: Assign one observation closest centroid. Recalculate centroids. Repeat observations reassigned . Repeat convergence. third common variant Hartigan-Wong method, assigns observations based overall sum squared errors rather simply closest cluster: Temporarily assign one observation one cluster. Recalculate centroid. Find distances observations cluster center (SSE). Repeat cluster. Permanently assign observation cluster resulted lowest SSE. Repeat observations. Repeat convergence. many interactive algorithms, choice methods choice complexity versus accuracy. Hartigan-Wong method generally results consistent human-verified clusterings, default setting stats::kmeans implementation k-means clustering; although three algorithms available options engine. Lloyd/Forgy method simple ubiquitous; method available ClusterR package implementation. Source","code":""},{"path":"/articles/k_means.html","id":"initialization-of-the-k-means-algorithm","dir":"Articles","previous_headings":"A brief introduction to the k-means algorithm","what":"Initialization of the k-means algorithm","title":"k-means","text":"k-means algorithm depends choosing initial set cluster centers. three common methods selecting initial centers: Random observations: example , chosen three random observations act initial centers. commonly used approach, implemented Forgy, Lloyd, MacQueen methods. Random partition: observations assigned cluster uniformly random. centroid cluster computed, used initial centers. approach implemented Hartigan-Wong method. k-means++: Beginning one random set observations, observations sampled via probability-weighted sampling \\(k\\) clusters formed. centroids clusters used initial centers. (detail ) initial conditions based random selection approaches, k-means algorithm determinitistic. , running clustering twice data may result cluster assignments. common perform k-means clustering algorithm multiple times, different random initial conditions, combine results end. option controlled nstart argument stats::kmeans implementation, num_init argument ","code":""},{"path":"/articles/tuning_and_metrics.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Tuning Cluster Models","text":"Important: Make sure install developer version parsnip workflows access current functionality tidyclust: Load libraries: Load clean dataset:","code":"remotes::install_github(\"tidymodels/parsnip\") remotes::install_github(\"tidymodels/workflows@celery\")  library(parsnip) library(workflows) library(tidyclust) library(tidyverse) library(tidymodels) data(\"penguins\", package = \"modeldata\")  penguins <- penguins %>%   drop_na()"},{"path":"/articles/tuning_and_metrics.html","id":"tuning-in-unsupervised-settings","dir":"Articles","previous_headings":"","what":"Tuning in unsupervised settings","title":"Tuning Cluster Models","text":"supervised modeling scenarios, observe values target (“response”) variable, measure success model based well predicts future response values. select hyperparameter values, tune , trying many possible values measuring well performs predicting target values test data. unsupervised modeling setting tidyclust, objective measure success. Clustering analyses typically exploratory rather testable. Nonetheless, core tuning principle varying inputs quantifying results still applicable.","code":""},{"path":"/articles/tuning_and_metrics.html","id":"specify-and-fit-a-model","dir":"Articles","previous_headings":"","what":"Specify and fit a model","title":"Tuning Cluster Models","text":"example, fit \\(k\\)-means cluster model palmerpenguins dataset, using bill length bill depth penguins predictors. (Please refer k-means vignette -depth discussion model specification.) goal select appropriate number clusters model based metrics. First, set cross-validation samples data: Next, specify model tuning parameter, make workflow, establish range possible values num_clusters try: , can use tune_cluster() compute metrics cross-validation split, possible choice number clusters.","code":"penguins_cv <- vfold_cv(penguins, v = 5) kmeans_spec <- k_means(num_clusters = tune())   penguins_rec <- recipe(~ bill_length_mm + bill_depth_mm,                         data = penguins)  kmeans_wflow <- workflow(penguins_rec, kmeans_spec)  clust_num_grid <- grid_regular(num_clusters(),                                 levels = 10)    clust_num_grid #> # A tibble: 10 × 1 #>    num_clusters #>           <int> #>  1            1 #>  2            2 #>  3            3 #>  4            4 #>  5            5 #>  6            6 #>  7            7 #>  8            8 #>  9            9 #> 10           10 res <- tune_cluster(   kmeans_wflow,   resamples = penguins_cv,   grid = clust_num_grid,   control = control_grid(save_pred = TRUE, extract = identity),   metrics = cluster_metric_set(tot_wss, tot_sse, sse_ratio) )   res #> # Tuning results #> # 5-fold cross-validation  #> # A tibble: 5 × 6 #>   splits           id    .metrics          .notes           .extracts .predict…¹ #>   <list>           <chr> <list>            <list>           <list>    <list>     #> 1 <split [266/67]> Fold1 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  <tibble>   #> 2 <split [266/67]> Fold2 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  <tibble>   #> 3 <split [266/67]> Fold3 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  <tibble>   #> 4 <split [267/66]> Fold4 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  <tibble>   #> 5 <split [267/66]> Fold5 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  <tibble>   #> # … with abbreviated variable name ¹​.predictions res_metrics <- res %>% collect_metrics() res_metrics #> # A tibble: 30 × 7 #>    num_clusters .metric   .estimator     mean     n   std_err .config            #>           <int> <chr>     <chr>         <dbl> <int>     <dbl> <chr>              #>  1            1 sse_ratio standard      1         5   0       Preprocessor1_Mod… #>  2            1 tot_sse   standard   8971.        5 119.      Preprocessor1_Mod… #>  3            1 tot_wss   standard   8971.        5 119.      Preprocessor1_Mod… #>  4            2 sse_ratio standard      0.321     5   0.00141 Preprocessor1_Mod… #>  5            2 tot_sse   standard   8971.        5 119.      Preprocessor1_Mod… #>  6            2 tot_wss   standard   2885.        5  47.3     Preprocessor1_Mod… #>  7            3 sse_ratio standard      0.202     5   0.00221 Preprocessor1_Mod… #>  8            3 tot_sse   standard   8971.        5 119.      Preprocessor1_Mod… #>  9            3 tot_wss   standard   1809.        5  34.7     Preprocessor1_Mod… #> 10            4 sse_ratio standard      0.160     5   0.00579 Preprocessor1_Mod… #> # … with 20 more rows"},{"path":"/articles/tuning_and_metrics.html","id":"choosing-hyperparameters","dir":"Articles","previous_headings":"Specify and fit a model","what":"Choosing hyperparameters","title":"Tuning Cluster Models","text":"supervised learning, choose model best value target metric. However, clustering models general local maxima minima. clusters model, always expect within sum--squares smaller. common approach choosing number clusters look “elbow”, notable bend, plot WSS/TSS ratio cluster number:  increase number clusters, WSS/TSS ratio decreases, amount decrease getting smaller number clusters grows. might argue drop two clusters three, three four, bit extreme subsequent drops, probably choose three four clusters.","code":"res_metrics %>%   filter(.metric == \"sse_ratio\") %>%   ggplot(aes(x = num_clusters, y = mean)) +   geom_point() +    geom_line() +    theme_minimal() +   ylab(\"mean WSS/TSS ratio, over 5 folds\") +   xlab(\"Number of clusters\") +   scale_x_continuous(breaks = 1:10)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Emil Hvitfeldt. Author, maintainer. Kelly Bodwin. Author. RStudio. Copyright holder, funder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hvitfeldt E, Bodwin K (2022). tidyclust: Common API Clustering. R package version 0.0.0.9000, https://github.com/EmilHvitfeldt/tidyclust.","code":"@Manual{,   title = {tidyclust: A Common API to Clustering},   author = {Emil Hvitfeldt and Kelly Bodwin},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://github.com/EmilHvitfeldt/tidyclust}, }"},{"path":"/index.html","id":"tidyclust-","dir":"","previous_headings":"","what":"A Common API to Clustering","title":"A Common API to Clustering","text":"goal tidyclust provide tidy, unified interface clustering models. packages closely modeled parsnip package.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Common API to Clustering","text":"can install development version tidyclust GitHub : Please note package currently requires branch workflows package work. Use caution.","code":"# install.packages(\"devtools\") devtools::install_github(\"EmilHvitfeldt/tidyclust\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"A Common API to Clustering","text":"first thing create cluster specification. example creating K-means model, using stats engine. specification can fit using data. fitted tidyclust object, can number things. predict() returns cluster new observation belongs extract_cluster_assignment() returns cluster assignments training observations extract_centroids() returns locations clusters","code":"library(tidyclust) set.seed(1234)  kmeans_spec <- k_means(num_clusters = 3) %>%   set_engine(\"stats\")   kmeans_spec #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 3 #>  #> Computational engine: stats kmeans_spec_fit <- kmeans_spec %>%   fit(~., data = mtcars) kmeans_spec_fit #> tidyclust cluster object #>  #> K-means clustering with 3 clusters of sizes 7, 14, 11 #>  #> Cluster means: #>        mpg cyl     disp        hp     drat       wt     qsec        vs #> 1 19.74286   6 183.3143 122.28571 3.585714 3.117143 17.97714 0.5714286 #> 2 15.10000   8 353.1000 209.21429 3.229286 3.999214 16.77214 0.0000000 #> 3 26.66364   4 105.1364  82.63636 4.070909 2.285727 19.13727 0.9090909 #>          am     gear     carb #> 1 0.4285714 3.857143 3.428571 #> 2 0.1428571 3.285714 3.500000 #> 3 0.7272727 4.090909 1.545455 #>  #> Clustering vector: #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   1                   1                   3                   1  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   2                   1                   2                   3  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   3                   1                   1                   2  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   2                   2                   2                   2  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   2                   3                   3                   3  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   3                   2                   2                   2  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   2                   3                   3                   3  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   2                   1                   2                   3  #>  #> Within cluster sum of squares by cluster: #> [1] 13954.34 93643.90 11848.37 #>  (between_SS / total_SS =  80.8 %) #>  #> Available components: #>  #> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" #> [6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\" predict(kmeans_spec_fit, mtcars[1:4, ]) #> # A tibble: 4 × 1 #>   .pred_cluster #>   <fct>         #> 1 Cluster_1     #> 2 Cluster_1     #> 3 Cluster_2     #> 4 Cluster_1 extract_cluster_assignment(kmeans_spec_fit) #> # A tibble: 32 × 1 #>    .cluster  #>    <fct>     #>  1 Cluster_1 #>  2 Cluster_1 #>  3 Cluster_2 #>  4 Cluster_1 #>  5 Cluster_3 #>  6 Cluster_1 #>  7 Cluster_3 #>  8 Cluster_2 #>  9 Cluster_2 #> 10 Cluster_1 #> # … with 22 more rows extract_centroids(kmeans_spec_fit) #> # A tibble: 3 × 12 #>   .cluster    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <fct>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Cluster_1  19.7     6  183. 122.   3.59  3.12  18.0 0.571 0.429  3.86  3.43 #> 2 Cluster_2  26.7     4  105.  82.6  4.07  2.29  19.1 0.909 0.727  4.09  1.55 #> 3 Cluster_3  15.1     8  353. 209.   3.23  4.00  16.8 0     0.143  3.29  3.5"},{"path":"/reference/ClusterR_kmeans_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple Wrapper around ClusterR kmeans — ClusterR_kmeans_fit","title":"Simple Wrapper around ClusterR kmeans — ClusterR_kmeans_fit","text":"wrapper runs ClusterR::KMeans_rcpp adds column names centroids field.","code":""},{"path":"/reference/ClusterR_kmeans_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple Wrapper around ClusterR kmeans — ClusterR_kmeans_fit","text":"","code":"ClusterR_kmeans_fit(   data,   clusters,   num_init = 1,   max_iters = 100,   initializer = \"kmeans++\",   fuzzy = FALSE,   verbose = FALSE,   CENTROIDS = NULL,   tol = 1e-04,   tol_optimal_init = 0.3,   seed = 1 )"},{"path":"/reference/ClusterR_kmeans_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple Wrapper around ClusterR kmeans — ClusterR_kmeans_fit","text":"data matrix data frame clusters number clusters num_init number times algorithm run different centroid seeds max_iters maximum number clustering iterations initializer method initialization. One , optimal_init, quantile_init, kmeans++ random. See details information fuzzy either TRUE FALSE. TRUE, prediction probabilities calculated using distance observations centroids verbose either TRUE FALSE, indicating whether progress printed clustering. CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data. tol float number. , case iteration (iteration > 1 iteration < max_iters) 'tol' greater squared norm centroids, kmeans converged tol_optimal_init tolerance value 'optimal_init' initializer. higher value , far appart centroids . seed integer value random number generator (RNG)","code":""},{"path":"/reference/ClusterR_kmeans_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple Wrapper around ClusterR kmeans — ClusterR_kmeans_fit","text":"list following attributes: clusters, fuzzy_clusters (fuzzy = TRUE), centroids, total_SSE, best_initialization, WCSS_per_cluster, obs_per_cluster, .SS_DIV_total.SS","code":""},{"path":"/reference/add_on_exports.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions required for tidyclust-adjacent packages — new_cluster_spec","title":"Functions required for tidyclust-adjacent packages — new_cluster_spec","text":"functions helpful creating new packages register new cluster specifications.","code":""},{"path":"/reference/add_on_exports.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions required for tidyclust-adjacent packages — new_cluster_spec","text":"","code":"new_cluster_spec(cls, args, eng_args, mode, method, engine)"},{"path":"/reference/augment.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment data with predictions — augment.cluster_fit","title":"Augment data with predictions — augment.cluster_fit","text":"augment() add column(s) predictions given data.","code":""},{"path":"/reference/augment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment data with predictions — augment.cluster_fit","text":"","code":"# S3 method for cluster_fit augment(x, new_data, ...)"},{"path":"/reference/augment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment data with predictions — augment.cluster_fit","text":"x cluster_fit object produced fit.cluster_spec() fit_xy.cluster_spec() . new_data data frame matrix. ... currently used.","code":""},{"path":"/reference/augment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Augment data with predictions — augment.cluster_fit","text":"partition models, .pred_cluster column added.","code":""},{"path":"/reference/augment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment data with predictions — augment.cluster_fit","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   augment(new_data = mtcars) #> # A tibble: 32 × 12 #>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb .pred_clu…¹ #>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <fct>       #>  1  21       6  160    110  3.9   2.62  16.5     0     1     4     4 Cluster_1   #>  2  21       6  160    110  3.9   2.88  17.0     0     1     4     4 Cluster_1   #>  3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1 Cluster_2   #>  4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1 Cluster_3   #>  5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2 Cluster_4   #>  6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1 Cluster_3   #>  7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4 Cluster_5   #>  8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2 Cluster_1   #>  9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2 Cluster_1   #> 10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4 Cluster_1   #> # … with 22 more rows, and abbreviated variable name ¹​.pred_cluster"},{"path":"/reference/avg_silhouette.html","id":null,"dir":"Reference","previous_headings":"","what":"Measures average silhouette across all observations — avg_silhouette","title":"Measures average silhouette across all observations — avg_silhouette","text":"Measures average silhouette across observations","code":""},{"path":"/reference/avg_silhouette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measures average silhouette across all observations — avg_silhouette","text":"","code":"avg_silhouette(object, ...)  # S3 method for cluster_fit avg_silhouette(object, new_data = NULL, dists = NULL, dist_fun = NULL, ...)  # S3 method for workflow avg_silhouette(object, new_data = NULL, dists = NULL, dist_fun = NULL, ...)  avg_silhouette_vec(   object,   new_data = NULL,   dists = NULL,   dist_fun = Rfast::Dist,   ... )"},{"path":"/reference/avg_silhouette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measures average silhouette across all observations — avg_silhouette","text":"object fitted kmeans tidyclust model ... arguments passed methods. new_data dataset predict .  NULL, uses trained clustering. dists distance matrix. Used new_data NULL. dist_fun function calculating distances observations. Defaults Euclidean distance processed data.","code":""},{"path":"/reference/avg_silhouette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measures average silhouette across all observations — avg_silhouette","text":"double; average silhouette.","code":""},{"path":"/reference/avg_silhouette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measures average silhouette across all observations — avg_silhouette","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  dists <- mtcars %>%   as.matrix() %>%   dist()  avg_silhouette(kmeans_fit, dists = dists) #> # A tibble: 1 × 3 #>   .metric        .estimator .estimate #>   <chr>          <chr>          <dbl> #> 1 avg_silhouette standard       0.458  avg_silhouette_vec(kmeans_fit, dists = dists) #> [1] 0.4576413"},{"path":"/reference/check_empty_ellipse_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Check to ensure that ellipses are empty — check_empty_ellipse_tidyclust","title":"Check to ensure that ellipses are empty — check_empty_ellipse_tidyclust","text":"Check ensure ellipses empty","code":""},{"path":"/reference/check_empty_ellipse_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check to ensure that ellipses are empty — check_empty_ellipse_tidyclust","text":"","code":"check_empty_ellipse_tidyclust(...)"},{"path":"/reference/check_empty_ellipse_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check to ensure that ellipses are empty — check_empty_ellipse_tidyclust","text":"... Extra arguments.","code":""},{"path":"/reference/check_empty_ellipse_tidyclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check to ensure that ellipses are empty — check_empty_ellipse_tidyclust","text":"error thrown (non-empty ellipses), NULL list.","code":""},{"path":"/reference/cluster_metric_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine metric functions — cluster_metric_set","title":"Combine metric functions — cluster_metric_set","text":"metric_set() allows combine multiple metric functions together new function calculates .","code":""},{"path":"/reference/cluster_metric_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine metric functions — cluster_metric_set","text":"","code":"cluster_metric_set(...)"},{"path":"/reference/cluster_metric_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine metric functions — cluster_metric_set","text":"... bare names functions included metric set.","code":""},{"path":"/reference/cluster_metric_set.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine metric functions — cluster_metric_set","text":"functions must : cluster metrics","code":""},{"path":"/reference/control_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Control the fit function — control_cluster","title":"Control the fit function — control_cluster","text":"Options can passed fit.cluster_spec() function control output computations.","code":""},{"path":"/reference/control_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control the fit function — control_cluster","text":"","code":"control_cluster(verbosity = 1L, catch = FALSE)"},{"path":"/reference/control_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control the fit function — control_cluster","text":"verbosity integer value zero indicates messages output shown packages loaded model fit. value 1 means package loading quiet model fits can produce output screen (depending contain verbose-type argument). value 2 indicates output seen. catch logical value TRUE evaluate model inside try(, silent = TRUE). model fails, object still returned (without error) inherits class \"try-error\".","code":""},{"path":"/reference/control_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control the fit function — control_cluster","text":"S3 object class \"control_cluster\" named list results function call","code":""},{"path":"/reference/convert_helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions to convert between formula and matrix interface — .convert_form_to_x_fit","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_x_fit","text":"Functions take formula interface get resulting objects (y, x, weights, etc) back way around. functions intended developer use. part, emulates internals lm() (also see notes https://developer.r-project.org/model-fitting-functions.html). .convert_form_to_x_fit() .convert_x_to_form_fit() data created modeling. .convert_form_to_x_fit() saves data objects well objects needed new data predicted (e.g. terms, etc.). .convert_form_to_x_new() .convert_x_to_form_new() used new samples predicted require predictors available.","code":""},{"path":"/reference/convert_helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_x_fit","text":"","code":".convert_form_to_x_fit(   formula,   data,   ...,   na.action = na.omit,   indicators = \"traditional\",   composition = \"data.frame\",   remove_intercept = TRUE )  .convert_x_to_form_fit(x, weights = NULL, remove_intercept = TRUE)  .convert_form_to_x_new(   object,   new_data,   na.action = stats::na.pass,   composition = \"data.frame\" )  .convert_x_to_form_new(object, new_data)"},{"path":"/reference/convert_helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions to convert between formula and matrix interface — .convert_form_to_x_fit","text":"formula object class formula (one can coerced class): symbolic description model fitted. data data frame containing relevant variables (e.g. predictors, case weights, etc). ... Additional arguments passed stats::model.frame(). na.action function indicates happen data contain NAs. indicators string describing whether create indicator/dummy variables factor predictors. Possible options \"none\", \"traditional\", \"one_hot\". composition string describing whether resulting x y returned \"matrix\" \"data.frame\". remove_intercept logical indicating whether remove intercept column model.matrix() finished. x matrix, sparse matrix, data frame predictors. models support sparse matrix input. See tidyclust::get_encoding_tidyclust() details. x column names. weights numeric vector containing weights. object object class cluster_fit. new_data rectangular data object, data frame.","code":""},{"path":"/reference/empty_ellipses.html","id":null,"dir":"Reference","previous_headings":"","what":"Get colors for tidyclust text. — get_tidyclust_colors","title":"Get colors for tidyclust text. — get_tidyclust_colors","text":"Get colors tidyclust text.","code":""},{"path":"/reference/empty_ellipses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get colors for tidyclust text. — get_tidyclust_colors","text":"","code":"get_tidyclust_colors()"},{"path":"/reference/enrichment.html","id":null,"dir":"Reference","previous_headings":"","what":"Measures relationship between cluster assignments and another categorical variable. — enrichment","title":"Measures relationship between cluster assignments and another categorical variable. — enrichment","text":"Measures relationship cluster assignments another categorical variable.","code":""},{"path":"/reference/enrichment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measures relationship between cluster assignments and another categorical variable. — enrichment","text":"","code":"enrichment(data, clusters, var)"},{"path":"/reference/enrichment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measures relationship between cluster assignments and another categorical variable. — enrichment","text":"data dataset clusters variable cluster assignments var variables enrichment","code":""},{"path":"/reference/enrichment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measures relationship between cluster assignments and another categorical variable. — enrichment","text":"p-value Chi-Square test relationship cluster assignments categorical variable.","code":""},{"path":"/reference/extract_centroids.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract clusters from model — extract_centroids","title":"Extract clusters from model — extract_centroids","text":"Extract clusters model","code":""},{"path":"/reference/extract_centroids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract clusters from model — extract_centroids","text":"","code":"extract_centroids(object, ...)"},{"path":"/reference/extract_centroids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract clusters from model — extract_centroids","text":"object cluster_spec object. ... arguments passed methods.","code":""},{"path":"/reference/extract_centroids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract clusters from model — extract_centroids","text":"","code":"set.seed(1234) kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   extract_centroids() #> # A tibble: 5 × 12 #>   .cluster    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <fct>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Cluster_1  19.9  5.71  167. 120.   3.71  3.11  18.5 0.571 0.429   4    3.57 #> 2 Cluster_2  14.6  8     340. 272.   3.68  3.54  15.1 0     0.5     4    5    #> 3 Cluster_3  13.7  8     443  206.   3.06  4.97  17.6 0     0       3    3.5  #> 4 Cluster_4  27.0  4     102.  81.4  4.09  2.20  18.8 0.9   0.8     4.1  1.5  #> 5 Cluster_5  17.1  7.71  295. 161.   3.05  3.60  17.7 0.143 0       3    2.29"},{"path":"/reference/extract_cluster_assignment.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract cluster assignments from model — extract_cluster_assignment","title":"Extract cluster assignments from model — extract_cluster_assignment","text":"Extract cluster assignments model","code":""},{"path":"/reference/extract_cluster_assignment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract cluster assignments from model — extract_cluster_assignment","text":"","code":"extract_cluster_assignment(object, ...)"},{"path":"/reference/extract_cluster_assignment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract cluster assignments from model — extract_cluster_assignment","text":"object cluster_spec object. ... arguments passed methods.","code":""},{"path":"/reference/extract_cluster_assignment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract cluster assignments from model — extract_cluster_assignment","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   extract_cluster_assignment() #> # A tibble: 32 × 1 #>    .cluster  #>    <fct>     #>  1 Cluster_1 #>  2 Cluster_1 #>  3 Cluster_1 #>  4 Cluster_2 #>  5 Cluster_3 #>  6 Cluster_2 #>  7 Cluster_4 #>  8 Cluster_1 #>  9 Cluster_1 #> 10 Cluster_1 #> # … with 22 more rows"},{"path":"/reference/extract_fit_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"S3 method get fitted model summary info depending engine","code":""},{"path":"/reference/extract_fit_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"","code":"extract_fit_summary(object, ...)"},{"path":"/reference/extract_fit_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"object fitted cluster_spec object ... arguments passed methods","code":""},{"path":"/reference/extract_fit_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"list various summary elements","code":""},{"path":"/reference/extract_fit_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"elements cluster_names cluster_assignments factors.","code":""},{"path":"/reference/extract_fit_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"S3 method to get fitted model summary info depending on engine — extract_fit_summary","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   extract_fit_summary() #> $cluster_names #> [1] Cluster_1 Cluster_2 Cluster_3 Cluster_4 Cluster_5 #> Levels: Cluster_1 Cluster_2 Cluster_3 Cluster_4 Cluster_5 #>  #> $centroids #> # A tibble: 5 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  16.4  8     302. 169.   3.04  3.66  17.4  0    0      3     2.5  #> 2  19.8  6     242. 108.   2.92  3.34  19.8  1    0      3     1    #> 3  13.7  8     443  206.   3.06  4.97  17.6  0    0      3     3.5  #> 4  14.6  8     340. 272.   3.68  3.54  15.1  0    0.5    4     5    #> 5  24.5  4.62  122.  96.9  4.00  2.52  18.5  0.75 0.688  4.12  2.44 #>  #> $n_members #> [1]  6  2  4  4 16 #>  #> $within_sse #> [1]  6815.5541   562.8304  4665.0415  7654.1463 32837.9972 #>  #> $tot_sse #> [1] 623387.5 #>  #> $orig_labels #>  [1] 3 3 3 2 5 2 4 3 3 3 3 5 5 5 1 1 1 3 3 3 3 5 5 4 1 3 3 3 4 3 4 3 #>  #> $cluster_assignments #>  [1] Cluster_1 Cluster_1 Cluster_1 Cluster_2 Cluster_3 Cluster_2 Cluster_4 #>  [8] Cluster_1 Cluster_1 Cluster_1 Cluster_1 Cluster_3 Cluster_3 Cluster_3 #> [15] Cluster_5 Cluster_5 Cluster_5 Cluster_1 Cluster_1 Cluster_1 Cluster_1 #> [22] Cluster_3 Cluster_3 Cluster_4 Cluster_5 Cluster_1 Cluster_1 Cluster_1 #> [29] Cluster_4 Cluster_1 Cluster_4 Cluster_1 #> Levels: Cluster_1 Cluster_2 Cluster_3 Cluster_4 Cluster_5 #>"},{"path":"/reference/finalize_model_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Splice final parameters into objects — finalize_model_tidyclust","title":"Splice final parameters into objects — finalize_model_tidyclust","text":"finalize_* functions take list tibble tuning parameter values update objects values.","code":""},{"path":"/reference/finalize_model_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splice final parameters into objects — finalize_model_tidyclust","text":"","code":"finalize_model_tidyclust(x, parameters)  finalize_workflow_tidyclust(x, parameters)"},{"path":"/reference/finalize_model_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splice final parameters into objects — finalize_model_tidyclust","text":"x recipe, parsnip model specification, workflow. parameters list 1-row tibble parameter values. Note column names tibble id fields attached tune(). example, Examples section , model tune(\"K\"). case, parameter tibble \"K\" \"neighbors\".","code":""},{"path":"/reference/finalize_model_tidyclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splice final parameters into objects — finalize_model_tidyclust","text":"updated version x.","code":""},{"path":"/reference/finalize_model_tidyclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splice final parameters into objects — finalize_model_tidyclust","text":"","code":"kmeans_spec <- k_means(num_clusters = tune())  best_params <- data.frame(num_clusters = 5) best_params #>   num_clusters #> 1            5  kmeans_spec #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = tune() #>  #> Computational engine: stats  #>  finalize_model_tidyclust(kmeans_spec, best_params) #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 5 #>  #> Computational engine: stats  #>"},{"path":"/reference/fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a Model Specification to a Data Set — fit.cluster_spec","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"fit() fit_xy() take model specification, translate_tidyclust required code substituting arguments, execute model fit routine.","code":""},{"path":"/reference/fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"","code":"# S3 method for cluster_spec fit(object, formula, data, control = control_cluster(), ...)  # S3 method for cluster_spec fit_xy(object, x, case_weights = NULL, control = control_cluster(), ...)"},{"path":"/reference/fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"object object class cluster_spec chosen engine (via set_engine()). formula object class formula (one can coerced class): symbolic description model fitted. data Optional, depending interface (see Details ). data frame containing relevant variables (e.g. predictors, case weights, etc). Note: needed, named argument used. control named list elements verbosity catch. See control_cluster(). ... currently used; values passed ignored. options required fit model passed using set_engine(). x matrix, sparse matrix, data frame predictors. models support sparse matrix input. See tidyclust::get_encoding_tidyclust() details. x column names. case_weights optional classed vector numeric case weights. must return TRUE hardhat::is_case_weights() run . See hardhat::frequency_weights() hardhat::importance_weights() examples.","code":""},{"path":"/reference/fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"cluster_fit object contains several elements: spec: model specification object (object call fit) fit: model executed without error, model object. Otherwise, try-error object error message. preproc: objects needed convert formula non-formula interface (terms object) return value also class related fitted model (e.g. \"_kmeans\") base class \"cluster_fit\".","code":""},{"path":"/reference/fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"fit() fit_xy() substitute current arguments model specification computational engine's code, check validity, fit model using data engine-specific code. Different model functions different interfaces (e.g. formula x/y) functions translate_tidyclust interface used fit() fit_xy() invoked one required underlying model. possible, functions attempt avoid making copies data. example, underlying model uses formula fit() invoked, original data references model fit. However, underlying model uses something else, x/y, formula evaluated data converted required format. case, calls resulting model objects reference temporary objects used fit model. model engine set, model's default engine used (discussed model page). verbosity option control_cluster() greater zero, warning produced. like use alternative method generating contrasts supplying formula fit(), set global option contrasts preferred method. example, might set : options(contrasts = c(unordered = \"contr.helmert\", ordered = \"contr.poly\")). See help page stats::contr.treatment() possible contrast types.","code":""},{"path":[]},{"path":"/reference/fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a Model Specification to a Data Set — fit.cluster_spec","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  kmeans_mod <- k_means(num_clusters = 5)  using_formula <-   kmeans_mod %>%   set_engine(\"stats\") %>%   fit(~., data = mtcars)  using_x <-   kmeans_mod %>%   set_engine(\"stats\") %>%   fit_xy(x = mtcars)  using_formula #> tidyclust cluster object #>  #> K-means clustering with 5 clusters of sizes 7, 7, 4, 10, 4 #>  #> Cluster means: #>        mpg cyl     disp        hp     drat       wt     qsec        vs #> 1 24.18571   4 121.7143  94.28571 3.924286 2.508286 19.10286 0.8571429 #> 2 19.74286   6 183.3143 122.28571 3.585714 3.117143 17.97714 0.5714286 #> 3 13.67500   8 443.0000 206.25000 3.060000 4.966000 17.56750 0.0000000 #> 4 15.67000   8 317.1400 210.40000 3.297000 3.612500 16.45400 0.0000000 #> 5 31.00000   4  76.1250  62.25000 4.327500 1.896250 19.19750 1.0000000 #>          am     gear     carb #> 1 0.5714286 4.142857 1.714286 #> 2 0.4285714 3.857143 3.428571 #> 3 0.0000000 3.000000 3.500000 #> 4 0.2000000 3.400000 3.500000 #> 5 1.0000000 4.000000 1.250000 #>  #> Clustering vector: #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   2                   2                   1                   2  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   4                   2                   4                   1  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   1                   2                   2                   4  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   4                   4                   3                   3  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   3                   5                   5                   5  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   1                   4                   4                   4  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   3                   5                   1                   1  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   4                   2                   4                   1  #>  #> Within cluster sum of squares by cluster: #> [1]  3616.8297 13954.3363  4665.0415 43649.5192   208.0365 #>  (between_SS / total_SS =  89.4 %) #>  #> Available components: #>  #> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" #> [6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"       using_x #> tidyclust cluster object #>  #> K-means clustering with 5 clusters of sizes 6, 16, 4, 2, 4 #>  #> Cluster means: #>        mpg   cyl     disp       hp   drat     wt     qsec   vs     am  gear #> 1 16.38333 8.000 301.5667 169.1667 3.0450 3.6625 17.36500 0.00 0.0000 3.000 #> 2 24.50000 4.625 122.2937  96.8750 4.0025 2.5180 18.54312 0.75 0.6875 4.125 #> 3 13.67500 8.000 443.0000 206.2500 3.0600 4.9660 17.56750 0.00 0.0000 3.000 #> 4 19.75000 6.000 241.5000 107.5000 2.9200 3.3375 19.83000 1.00 0.0000 3.000 #> 5 14.60000 8.000 340.5000 272.2500 3.6750 3.5375 15.08750 0.00 0.5000 4.000 #>     carb #> 1 2.5000 #> 2 2.4375 #> 3 3.5000 #> 4 1.0000 #> 5 5.0000 #>  #> Clustering vector: #>           Mazda RX4       Mazda RX4 Wag          Datsun 710      Hornet 4 Drive  #>                   2                   2                   2                   4  #>   Hornet Sportabout             Valiant          Duster 360           Merc 240D  #>                   1                   4                   5                   2  #>            Merc 230            Merc 280           Merc 280C          Merc 450SE  #>                   2                   2                   2                   1  #>          Merc 450SL         Merc 450SLC  Cadillac Fleetwood Lincoln Continental  #>                   1                   1                   3                   3  #>   Chrysler Imperial            Fiat 128         Honda Civic      Toyota Corolla  #>                   3                   2                   2                   2  #>       Toyota Corona    Dodge Challenger         AMC Javelin          Camaro Z28  #>                   2                   1                   1                   5  #>    Pontiac Firebird           Fiat X1-9       Porsche 914-2        Lotus Europa  #>                   3                   2                   2                   2  #>      Ford Pantera L        Ferrari Dino       Maserati Bora          Volvo 142E  #>                   5                   2                   5                   2  #>  #> Within cluster sum of squares by cluster: #> [1]  6815.5541 32837.9972  4665.0415   562.8304  7654.1463 #>  (between_SS / total_SS =  91.6 %) #>  #> Available components: #>  #> [1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" #> [6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\""},{"path":"/reference/get_centroid_dists.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes distance from observations to centroids — get_centroid_dists","title":"Computes distance from observations to centroids — get_centroid_dists","text":"Computes distance observations centroids","code":""},{"path":"/reference/get_centroid_dists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes distance from observations to centroids — get_centroid_dists","text":"","code":"get_centroid_dists(new_data, centroids, dist_fun = Rfast::dista)"},{"path":"/reference/get_centroid_dists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes distance from observations to centroids — get_centroid_dists","text":"new_data data frame centroids data frame row centroid. dist_fun function computing matrix--matrix distances. Defaults Rfast::dista()","code":""},{"path":"/reference/get_model_env_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Working with the tidyclust model environment — get_model_env_tidyclust","title":"Working with the tidyclust model environment — get_model_env_tidyclust","text":"functions read write environment package stores information model specifications.","code":""},{"path":"/reference/get_model_env_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Working with the tidyclust model environment — get_model_env_tidyclust","text":"","code":"get_model_env_tidyclust()  get_from_env_tidyclust(items)  set_env_val_tidyclust(name, value)"},{"path":"/reference/get_model_env_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Working with the tidyclust model environment — get_model_env_tidyclust","text":"items character string objects model environment. name single character value new symbol model environment. value single value new value model environment. ... Named values assigned model environment.","code":""},{"path":"/reference/get_model_env_tidyclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Working with the tidyclust model environment — get_model_env_tidyclust","text":"","code":"# Access the model data: current_code <- get_model_env_tidyclust() ls(envir = current_code) #>  [1] \"hier_clust\"          \"hier_clust_args\"     \"hier_clust_encoding\" #>  [4] \"hier_clust_fit\"      \"hier_clust_modes\"    \"hier_clust_pkgs\"     #>  [7] \"hier_clust_predict\"  \"k_means\"             \"k_means_args\"        #> [10] \"k_means_encoding\"    \"k_means_fit\"         \"k_means_modes\"       #> [13] \"k_means_pkgs\"        \"k_means_predict\"     \"models\"              #> [16] \"modes\""},{"path":"/reference/glance.cluster_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a single row summary ","title":"Construct a single row summary ","text":"method glances model tidyclust model object, exists.","code":""},{"path":"/reference/glance.cluster_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a single row summary ","text":"","code":"# S3 method for cluster_fit glance(x, ...)"},{"path":"/reference/glance.cluster_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a single row summary ","text":"x model R object convert single-row data frame ... arguments passed methods","code":""},{"path":"/reference/glance.cluster_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a single row summary ","text":"tibble","code":""},{"path":"/reference/hclust_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple Wrapper around hclust function — hclust_fit","title":"Simple Wrapper around hclust function — hclust_fit","text":"wrapper prepares data distance matrix send stats::hclust retains parameters num_clusters h attribute.","code":""},{"path":"/reference/hclust_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple Wrapper around hclust function — hclust_fit","text":"","code":"hclust_fit(   x,   num_clusters = NULL,   cut_height = NULL,   linkage_method = NULL,   dist_fun = Rfast::Dist )"},{"path":"/reference/hclust_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple Wrapper around hclust function — hclust_fit","text":"x matrix data frame num_clusters number clusters linkage_method agglomeration method used. (unambiguous abbreviation ) one \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"average\" (= UPGMA), \"mcquitty\" (= WPGMA), \"median\" (= WPGMC) \"centroid\" (= UPGMC). dist_fun distance function use h height cut dendrogram","code":""},{"path":"/reference/hclust_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple Wrapper around hclust function — hclust_fit","text":"dendrogram","code":""},{"path":"/reference/hier_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Hierarchical (Agglomerative) Clustering — hier_clust","title":"Hierarchical (Agglomerative) Clustering — hier_clust","text":"hier_clust() defines model fits clusters based distance-based dendrogram","code":""},{"path":"/reference/hier_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hierarchical (Agglomerative) Clustering — hier_clust","text":"","code":"hier_clust(   mode = \"partition\",   engine = \"stats\",   num_clusters = NULL,   cut_height = NULL,   linkage_method = \"complete\" )"},{"path":"/reference/hier_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hierarchical (Agglomerative) Clustering — hier_clust","text":"mode single character string type model. possible value model \"partition\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"stats\". num_clusters Positive integer, number clusters model (optional). cut_height Positive double, height cut dendrogram obtain cluster assignments (used num_clusters NULL) linkage_method agglomeration method used. (unambiguous abbreviation ) one \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"average\" (= UPGMA), \"mcquitty\" (= WPGMA), \"median\" (= WPGMC) \"centroid\" (= UPGMC).","code":""},{"path":"/reference/hier_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hierarchical (Agglomerative) Clustering — hier_clust","text":"","code":"# show_engines(\"hier_clust\")  hier_clust() #> Hierarchical Clustering Specification (partition) #>  #> Main Arguments: #>   linkage_method = complete #>  #> Computational engine: stats  #>"},{"path":"/reference/k_means.html","id":null,"dir":"Reference","previous_headings":"","what":"K-Means — k_means","title":"K-Means — k_means","text":"k_means() defines model fits clusters based distances number centers.","code":""},{"path":"/reference/k_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-Means — k_means","text":"","code":"k_means(mode = \"partition\", engine = \"stats\", num_clusters = NULL)"},{"path":"/reference/k_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-Means — k_means","text":"mode single character string type model. possible value model \"partition\". engine single character string specifying computational engine use fitting. Possible engines listed . default model \"stats\". num_clusters Positive integer, number clusters model.","code":""},{"path":"/reference/k_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-Means — k_means","text":"","code":"# show_engines(\"k_means\")  k_means() #> K Means Cluster Specification (partition) #>  #> Computational engine: stats  #>"},{"path":"/reference/make_classes_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepend a new class — make_classes_tidyclust","title":"Prepend a new class — make_classes_tidyclust","text":"adds extra class base class \"cluster_spec\".","code":""},{"path":"/reference/make_classes_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepend a new class — make_classes_tidyclust","text":"","code":"make_classes_tidyclust(prefix)"},{"path":"/reference/make_classes_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepend a new class — make_classes_tidyclust","text":"prefix character string class.","code":""},{"path":"/reference/make_classes_tidyclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepend a new class — make_classes_tidyclust","text":"character vector.","code":""},{"path":"/reference/new_cluster_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a new clustering metric function — new_cluster_metric","title":"Construct a new clustering metric function — new_cluster_metric","text":"functions provide convenient wrappers create one type metric functions celrry: clustering metrics. add metric-specific class fn. features used cluster_metric_set() tune_cluster() tuning.","code":""},{"path":"/reference/new_cluster_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a new clustering metric function — new_cluster_metric","text":"","code":"new_cluster_metric(fn, direction)"},{"path":"/reference/new_cluster_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a new clustering metric function — new_cluster_metric","text":"fn function. direction string. One : \"maximize\" \"minimize\" \"zero\"","code":""},{"path":"/reference/num_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Clusters — num_clusters","title":"Number of Clusters — num_clusters","text":"Number Clusters","code":""},{"path":"/reference/num_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Clusters — num_clusters","text":"","code":"num_clusters(range = c(1L, 10L), trans = NULL)"},{"path":"/reference/num_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of Clusters — num_clusters","text":"range two-element vector holding defaults smallest largest possible values, respectively. transformation specified, values transformed units. trans trans object scales package, scales::log10_trans() scales::reciprocal_trans(). provided, default used matches units used range. transformation, NULL.","code":""},{"path":"/reference/num_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Clusters — num_clusters","text":"","code":"num_clusters() #> # Clusters (quantitative) #> Range: [1, 10]"},{"path":"/reference/other_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Other predict methods. — predict_cluster","title":"Other predict methods. — predict_cluster","text":"internal functions meant directly called user.","code":""},{"path":"/reference/other_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Other predict methods. — predict_cluster","text":"","code":"predict_cluster(object, ...)  # S3 method for cluster_fit predict_cluster(object, new_data, ...)"},{"path":"/reference/other_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Other predict methods. — predict_cluster","text":"object object class cluster_fit ... Arguments underlying model's prediction function passed (see opts). new_data rectangular data object, data frame.","code":""},{"path":"/reference/predict.cluster_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions — predict.cluster_fit","title":"Model predictions — predict.cluster_fit","text":"Apply model create different types predictions. predict() can used types models uses \"type\" argument specificity.","code":""},{"path":"/reference/predict.cluster_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions — predict.cluster_fit","text":"","code":"# S3 method for cluster_fit predict(object, new_data, type = NULL, opts = list(), ...)  # S3 method for cluster_fit predict_raw(object, new_data, opts = list(), ...)"},{"path":"/reference/predict.cluster_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions — predict.cluster_fit","text":"object object class cluster_fit new_data rectangular data object, data frame. type single character value NULL. Possible values \"cluster\", \"raw\". NULL, predict() choose appropriate value based model's mode. opts list optional arguments underlying predict function used type = \"raw\". list include options model object new data predicted. ... Arguments underlying model's prediction function passed (see opts).","code":""},{"path":"/reference/predict.cluster_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions — predict.cluster_fit","text":"exception type = \"raw\", results predict.cluster_fit() tibble many rows output rows new_data column names predictable. clustering results tibble .pred_cluster column. Using type = \"raw\" predict.cluster_fit() return unadulterated results prediction function. model fit failed error captured, predict() function return structure filled missing values. currently work multivariate models.","code":""},{"path":"/reference/predict.cluster_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model predictions — predict.cluster_fit","text":"\"type\" supplied predict(), choice made: type = \"cluster\" clustering models predict() designed provide tidy result (see \"Value\" section ) tibble output format.","code":""},{"path":"/reference/predict.cluster_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model predictions — predict.cluster_fit","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   predict(new_data = mtcars) #> # A tibble: 32 × 1 #>    .pred_cluster #>    <fct>         #>  1 Cluster_1     #>  2 Cluster_1     #>  3 Cluster_2     #>  4 Cluster_3     #>  5 Cluster_4     #>  6 Cluster_1     #>  7 Cluster_4     #>  8 Cluster_2     #>  9 Cluster_2     #> 10 Cluster_1     #> # … with 22 more rows"},{"path":"/reference/prep_data_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepares data and distance matrices for metric calculation — prep_data_dist","title":"Prepares data and distance matrices for metric calculation — prep_data_dist","text":"Prepares data distance matrices metric calculation","code":""},{"path":"/reference/prep_data_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepares data and distance matrices for metric calculation — prep_data_dist","text":"","code":"prep_data_dist(object, new_data = NULL, dists = NULL, dist_fun = Rfast::Dist)"},{"path":"/reference/prep_data_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepares data and distance matrices for metric calculation — prep_data_dist","text":"object fitted cluster_spec object. new_data dataset calculate predictions .  NULL, trained cluster assignments fitted object used. dists distance matrix data.  NULL, distance computed new_data using stats::dist() function. dist_fun custom distance functions.","code":""},{"path":"/reference/prep_data_dist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepares data and distance matrices for metric calculation — prep_data_dist","text":"list","code":""},{"path":"/reference/prepare_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data based on parsnip encoding information — prepare_data","title":"Prepare data based on parsnip encoding information — prepare_data","text":"Prepare data based parsnip encoding information","code":""},{"path":"/reference/prepare_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data based on parsnip encoding information — prepare_data","text":"","code":"prepare_data(object, new_data)"},{"path":"/reference/prepare_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data based on parsnip encoding information — prepare_data","text":"object parsnip model object new_data data frame","code":""},{"path":"/reference/prepare_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data based on parsnip encoding information — prepare_data","text":"data frame matrix","code":""},{"path":"/reference/reconcile_clusterings.html","id":null,"dir":"Reference","previous_headings":"","what":"Relabels clusters to match another cluster assignment — reconcile_clusterings","title":"Relabels clusters to match another cluster assignment — reconcile_clusterings","text":"Retains cluster labels primary assignment, relabel alternate assignment match closely possible.  user must decide whether clusters forced \"one--one\"; , allowed assign multiple labels alternate assignment primary label?","code":""},{"path":"/reference/reconcile_clusterings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relabels clusters to match another cluster assignment — reconcile_clusterings","text":"","code":"reconcile_clusterings(   primary_cluster_assignment,   alt_cluster_assignment,   one_to_one = TRUE,   optimize = \"accuracy\" )"},{"path":"/reference/reconcile_clusterings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relabels clusters to match another cluster assignment — reconcile_clusterings","text":"primary_cluster_assignment vector containing cluster labels, matched alt_cluster_assignment Another vector containing cluster labels, changed one_to_one Boolean; alt cluster match one primary cluster? optimize One \"accuracy\" \"precision\"; see description.","code":""},{"path":"/reference/reconcile_clusterings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Relabels clusters to match another cluster assignment — reconcile_clusterings","text":"vector new cluster labels","code":""},{"path":"/reference/reconcile_clusterings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Relabels clusters to match another cluster assignment — reconcile_clusterings","text":"forcing one--one, user needs decide prioritize: \"accuracy\": optimize raw count observations label across two assignments \"precision\": optimize average percent alt cluster matches corresponding primary cluster","code":""},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics augment, fit, fit_xy, glance, min_grid, required_pkgs, tidy hardhat extract_fit_parsnip, extract_parameter_set_dials, extract_preprocessor, extract_spec_parsnip, tune magrittr %>% parsnip predict_raw, set_args, set_engine, set_mode tune load_pkgs","code":""},{"path":"/reference/set_new_model_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Tools to Register Models — set_new_model_tidyclust","title":"Tools to Register Models — set_new_model_tidyclust","text":"functions similar constructors can used validate conflicts underlying model structures used package.","code":""},{"path":"/reference/set_new_model_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tools to Register Models — set_new_model_tidyclust","text":"","code":"set_new_model_tidyclust(model)  check_model_doesnt_exist_tidyclust(model)  set_model_mode_tidyclust(model, mode)  check_model_exists_tidyclust(model)  set_model_engine_tidyclust(model, mode, eng)  set_dependency_tidyclust(model, eng, pkg = \"tidyclust\", mode = NULL)  get_dependency_tidyclust(model)  set_fit_tidyclust(model, mode, eng, value)  get_fit_tidyclust(model)  get_encoding_tidyclust(model)  set_encoding_tidyclust(model, mode, eng, options)  set_model_arg_tidyclust(model, eng, tidyclust, original, func, has_submodel)  show_model_info_tidyclust(model)  set_pred_tidyclust(model, mode, eng, type, value)  get_pred_type_tidyclust(model, type)"},{"path":"/reference/set_new_model_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tools to Register Models — set_new_model_tidyclust","text":"model single character string model type (e.g. \"k_means\", etc). mode single character string model mode (e.g. \"partition\"). eng single character string model engine. pkg options character string package name. value list conforms fit_obj pred_obj description , depending context. options list options engine-specific preprocessing encodings. See Details . tidyclust single character string \"harmonized\" argument name tidyclust exposes. original single character string argument name underlying model function uses. func named character vector describes call function. func elements pkg fun. former optional recommended latter required. example, c(pkg = \"stats\", fun = \"lm\") used invoke usual linear regression function. cases, helpful use c(fun = \"predict\") using package's predict method. has_submodel single logical whether argument can make predictions multiple submodels . type single character value type prediction. Possible values : cluster raw. arg single character string model argument name. fit_obj list elements interface, protect, func defaults. See package vignette \"Making tidyclust model scratch\". pred_obj list elements pre, post, func, args. pre, post Optional functions pre- post-processing prediction results. ... Optional arguments passed args slot prediction objects.","code":""},{"path":"/reference/set_new_model_tidyclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tools to Register Models — set_new_model_tidyclust","text":"functions available users add models engines (package otherwise) can accessed using tidyclust. short, tidyclust stores environment object contains information code models used (e.g. fitting, predicting, etc). functions can used add models environment well helper functions can used makes sure model data right format. check_model_exists_tidyclust() checks model value ensures model already registered. check_model_doesnt_exist_tidyclust() checks model value also checks see novel environment. options engine-specific encodings dictate predictors handled. options ensure data tidyclust gives underlying model allows model fit similar possible produced directly. example, fit() used fit model formula interface, typically predictor preprocessing must conducted. glmnet good example . four options can used encodings: predictor_indicators describes whether create indicator/dummy variables factor predictors. three options: \"none\" (expand factor predictors), \"traditional\" (apply standard model.matrix() encodings), \"one_hot\" (create complete set including baseline level factors). encoding affects cases fit.cluster_spec() used underlying model x/y interface. Another option compute_intercept; controls whether model.matrix() include intercept formula. affects inclusion intercept column. intercept, model.matrix() computes dummy variables one factor levels. Without intercept, model.matrix() computes full set indicators first factor variable, incomplete set remainder. Next, option remove_intercept remove intercept column model.matrix() finished. can useful model function (e.g. lm()) automatically generates intercept. Finally, allow_sparse_x specifies whether model function can natively accommodate sparse matrix representation predictors fitting tuning.","code":""},{"path":"/reference/set_new_model_tidyclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tools to Register Models — set_new_model_tidyclust","text":"","code":"# set_new_model_tidyclust(\"shallow_learning_model\")  # Show the information about a model: show_model_info_tidyclust(\"k_means\") #> Information for `k_means` #>  modes: unknown, partition  #>  #>  engines:  #>    partition: ClusterR, stats #>  #>  arguments:  #>    stats:     #>       num_clusters --> centers #>    ClusterR:  #>       num_clusters --> clusters #>  #>  fit modules: #>      engine      mode #>       stats partition #>    ClusterR partition #>  #>  prediction modules: #>         mode   engine methods #>    partition ClusterR cluster #>    partition    stats cluster #>"},{"path":"/reference/silhouettes.html","id":null,"dir":"Reference","previous_headings":"","what":"Measures silhouettes between clusters — silhouettes","title":"Measures silhouettes between clusters — silhouettes","text":"Measures silhouettes clusters","code":""},{"path":"/reference/silhouettes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measures silhouettes between clusters — silhouettes","text":"","code":"silhouettes(object, new_data = NULL, dists = NULL, dist_fun = Rfast::Dist)"},{"path":"/reference/silhouettes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measures silhouettes between clusters — silhouettes","text":"object fitted tidyclust model new_data dataset predict .  NULL, uses trained clustering. dists distance matrix. Used new_data NULL. dist_fun function calculating distances observations. Defaults Euclidean distance processed data.","code":""},{"path":"/reference/silhouettes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measures silhouettes between clusters — silhouettes","text":"tibble giving silhouettes observation.","code":""},{"path":"/reference/silhouettes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measures silhouettes between clusters — silhouettes","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  dists <- mtcars %>%   as.matrix() %>%   dist()  silhouettes(kmeans_fit, dists = dists) #> # A tibble: 32 × 3 #>    cluster   neighbor  sil_width #>    <fct>     <fct>         <dbl> #>  1 Cluster_1 Cluster_2     0.572 #>  2 Cluster_1 Cluster_2     0.572 #>  3 Cluster_1 Cluster_2     0.752 #>  4 Cluster_2 Cluster_1     0.540 #>  5 Cluster_3 Cluster_4     0.149 #>  6 Cluster_2 Cluster_1     0.224 #>  7 Cluster_3 Cluster_4     0.649 #>  8 Cluster_1 Cluster_2     0.613 #>  9 Cluster_1 Cluster_2     0.692 #> 10 Cluster_1 Cluster_2     0.460 #> # … with 22 more rows"},{"path":"/reference/sse_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the ratio of the WSS to the total SSE — sse_ratio","title":"Compute the ratio of the WSS to the total SSE — sse_ratio","text":"Compute ratio WSS total SSE","code":""},{"path":"/reference/sse_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the ratio of the WSS to the total SSE — sse_ratio","text":"","code":"sse_ratio(object, ...)  # S3 method for cluster_fit sse_ratio(object, new_data = NULL, dist_fun = NULL, ...)  # S3 method for workflow sse_ratio(object, new_data = NULL, dist_fun = NULL, ...)  sse_ratio_vec(object, new_data = NULL, dist_fun = Rfast::dista, ...)"},{"path":"/reference/sse_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the ratio of the WSS to the total SSE — sse_ratio","text":"object fitted kmeans tidyclust model ... arguments passed methods. new_data dataset predict .  NULL, uses trained clustering. dist_fun function calculating distances centroids.  Defaults Euclidean distance processed data.","code":""},{"path":"/reference/sse_ratio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the ratio of the WSS to the total SSE — sse_ratio","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   sse_ratio() #> # A tibble: 1 × 3 #>   .metric   .estimator .estimate #>   <chr>     <chr>          <dbl> #> 1 sse_ratio standard       0.107"},{"path":"/reference/tidy.cluster_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Turn a tidyclust model object into a tidy tibble — tidy.cluster_fit","title":"Turn a tidyclust model object into a tidy tibble — tidy.cluster_fit","text":"method tidies model tidyclust model object, exists.","code":""},{"path":"/reference/tidy.cluster_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Turn a tidyclust model object into a tidy tibble — tidy.cluster_fit","text":"","code":"# S3 method for cluster_fit tidy(x, ...)"},{"path":"/reference/tidy.cluster_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Turn a tidyclust model object into a tidy tibble — tidy.cluster_fit","text":"x object converted tidy tibble::tibble(). ... Additional arguments tidying method.","code":""},{"path":"/reference/tidy.cluster_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Turn a tidyclust model object into a tidy tibble — tidy.cluster_fit","text":"tibble","code":""},{"path":"/reference/tidyclust-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tidyclust: A Common API to Clustering — tidyclust-package","title":"tidyclust: A Common API to Clustering — tidyclust-package","text":"common interface specifying clustering models, style `parsnip`. Creates unified interface across different functions computational engines.","code":""},{"path":[]},{"path":"/reference/tidyclust-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"tidyclust: A Common API to Clustering — tidyclust-package","text":"Maintainer: Emil Hvitfeldt emilhhvitfeldt@gmail.com (ORCID) Authors: Kelly Bodwin kelly@bodwin.us contributors: RStudio [copyright holder, funder]","code":""},{"path":"/reference/tidyclust_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a cluster specification — update.hier_clust","title":"Update a cluster specification — update.hier_clust","text":"parameters cluster specification need modified, update() can used lieu recreating object scratch.","code":""},{"path":"/reference/tidyclust_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a cluster specification — update.hier_clust","text":"","code":"# S3 method for hier_clust update(   object,   parameters = NULL,   num_clusters = NULL,   cut_height = NULL,   linkage_method = NULL,   fresh = FALSE,   ... )  # S3 method for k_means update(object, parameters = NULL, num_clusters = NULL, fresh = FALSE, ...)"},{"path":"/reference/tidyclust_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a cluster specification — update.hier_clust","text":"object cluster specification. parameters 1-row tibble named list main parameters update. Use either parameters main arguments directly updating. main arguments used, supersede values parameters. Also, using engine arguments object result error. num_clusters Positive integer, number clusters model. cut_height Positive double, height cut dendrogram obtain cluster assignments (used num_clusters NULL) linkage_method agglomeration method used. (unambiguous abbreviation ) one \"ward.D\", \"ward.D2\", \"single\", \"complete\", \"average\" (= UPGMA), \"mcquitty\" (= WPGMA), \"median\" (= WPGMC) \"centroid\" (= UPGMC). fresh logical whether arguments modified -place replaced wholesale. ... used update().","code":""},{"path":"/reference/tidyclust_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update a cluster specification — update.hier_clust","text":"updated cluster specification.","code":""},{"path":"/reference/tidyclust_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update a cluster specification — update.hier_clust","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) kmeans_spec #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 5 #>  #> Computational engine: stats  #>  update(kmeans_spec, num_clusters = 1) #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 1 #>  #> Computational engine: stats  #>  update(kmeans_spec, num_clusters = 1, fresh = TRUE) #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 1 #>  #> Computational engine: stats  #>   param_values <- tibble::tibble(num_clusters = 10)  kmeans_spec %>% update(param_values) #> K Means Cluster Specification (partition) #>  #> Main Arguments: #>   num_clusters = 10 #>  #> Computational engine: stats  #>"},{"path":"/reference/tot_sse.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the total sum of squares — tot_sse","title":"Compute the total sum of squares — tot_sse","text":"Compute total sum squares","code":""},{"path":"/reference/tot_sse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the total sum of squares — tot_sse","text":"","code":"tot_sse(object, ...)  # S3 method for cluster_fit tot_sse(object, new_data = NULL, dist_fun = NULL, ...)  # S3 method for workflow tot_sse(object, new_data = NULL, dist_fun = NULL, ...)  tot_sse_vec(object, new_data = NULL, dist_fun = Rfast::dista, ...)"},{"path":"/reference/tot_sse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the total sum of squares — tot_sse","text":"object fitted kmeans tidyclust model ... arguments passed methods. new_data dataset predict .  NULL, uses trained clustering. dist_fun function calculating distances centroids.  Defaults Euclidean distance processed data.","code":""},{"path":"/reference/tot_sse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the total sum of squares — tot_sse","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   tot_sse() #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 tot_sse standard     623387.  kmeans_fit %>%   tot_sse_vec() #> [1] 623387.5"},{"path":"/reference/tot_wss.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the sum of within-cluster SSE — tot_wss","title":"Compute the sum of within-cluster SSE — tot_wss","text":"Compute sum within-cluster SSE","code":""},{"path":"/reference/tot_wss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the sum of within-cluster SSE — tot_wss","text":"","code":"tot_wss(object, ...)  # S3 method for cluster_fit tot_wss(object, new_data = NULL, dist_fun = NULL, ...)  # S3 method for workflow tot_wss(object, new_data = NULL, dist_fun = NULL, ...)  tot_wss_vec(object, new_data = NULL, dist_fun = Rfast::dista, ...)"},{"path":"/reference/tot_wss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the sum of within-cluster SSE — tot_wss","text":"object fitted kmeans tidyclust model ... arguments passed methods. new_data dataset predict .  NULL, uses trained clustering. dist_fun function calculating distances centroids.  Defaults Euclidean distance processed data.","code":""},{"path":"/reference/tot_wss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the sum of within-cluster SSE — tot_wss","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   tot_wss() #> # A tibble: 1 × 3 #>   .metric .estimator .estimate #>   <chr>   <chr>          <dbl> #> 1 tot_wss standard      64096.  kmeans_fit %>%   tot_wss_vec() #> [1] 64096.21"},{"path":"/reference/translate_tidyclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Resolve a Model Specification for a Computational Engine — translate_tidyclust","title":"Resolve a Model Specification for a Computational Engine — translate_tidyclust","text":"translate_tidyclust() translate_tidyclust model specification code object specific particular engine (e.g. R package). translate_tidyclusts generic parameters counterparts.","code":""},{"path":"/reference/translate_tidyclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resolve a Model Specification for a Computational Engine — translate_tidyclust","text":"","code":"translate_tidyclust(x, ...)  # S3 method for default translate_tidyclust(x, engine = x$engine, ...)"},{"path":"/reference/translate_tidyclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resolve a Model Specification for a Computational Engine — translate_tidyclust","text":"x model specification. ... currently used. engine computational engine model (see ?set_engine).","code":""},{"path":"/reference/translate_tidyclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Resolve a Model Specification for a Computational Engine — translate_tidyclust","text":"translate_tidyclust() produces template call lacks specific argument values (data, etc). filled fit() called specifics data model. call may also include tune() arguments specification. handle tune() arguments, need use tune package. information see https://www.tidymodels.org/start/tuning/ contain resolved argument names specific model fitting function/engine. function can useful need understand tidyclust goes generic model specific model fitting function. Note: function used internally users use understand underlying syntax . used modify cluster specification.","code":""},{"path":"/reference/tune_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Model tuning via grid search — tune_cluster","title":"Model tuning via grid search — tune_cluster","text":"tune_cluster() computes set performance metrics (e.g. accuracy RMSE) pre-defined set tuning parameters correspond model recipe across one resamples data.","code":""},{"path":"/reference/tune_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model tuning via grid search — tune_cluster","text":"","code":"tune_cluster(object, ...)  # S3 method for cluster_spec tune_cluster(   object,   preprocessor,   resamples,   ...,   param_info = NULL,   grid = 10,   metrics = NULL,   control = tune::control_grid() )  # S3 method for workflow tune_cluster(   object,   resamples,   ...,   param_info = NULL,   grid = 10,   metrics = NULL,   control = tune::control_grid() )"},{"path":"/reference/tune_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model tuning via grid search — tune_cluster","text":"object tidyclust model specification workflows::workflow(). ... currently used. preprocessor traditional model formula recipe created using recipes::recipe(). resamples rset() object. param_info dials::parameters() object NULL. none given, parameters set derived arguments. Passing argument can useful parameter ranges need customized. grid data frame tuning combinations positive integer. data frame columns parameter tuned rows tuning parameter candidates. integer denotes number candidate parameter sets created automatically. metrics cluster_metric_set() NULL. control object used modify tuning process. Defaults tune::control_grid().","code":""},{"path":"/reference/tune_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model tuning via grid search — tune_cluster","text":"updated version resamples extra list columns .metrics .notes (optional columns .predictions .extracts). .notes contains warnings errors occur execution.","code":""},{"path":"/reference/tune_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model tuning via grid search — tune_cluster","text":"","code":"1 + 1 #> [1] 2"},{"path":"/reference/within_cluster_sse.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","title":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","text":"Calculates Sum Squared Error cluster","code":""},{"path":"/reference/within_cluster_sse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","text":"","code":"within_cluster_sse(object, new_data = NULL, dist_fun = Rfast::dista)"},{"path":"/reference/within_cluster_sse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","text":"object fitted kmeans tidyclust model new_data dataset predict .  NULL, uses trained clustering. dist_fun function calculating distances centroids.  Defaults Euclidean distance processed data.","code":""},{"path":"/reference/within_cluster_sse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","text":"tibble two columns, cluster name SSE within cluster.","code":""},{"path":"/reference/within_cluster_sse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates Sum of Squared Error in each cluster — within_cluster_sse","text":"","code":"kmeans_spec <- k_means(num_clusters = 5) %>%   set_engine(\"stats\")  kmeans_fit <- fit(kmeans_spec, ~., mtcars)  kmeans_fit %>%   within_cluster_sse() #> # A tibble: 5 × 3 #>   .cluster     wss n_members #>   <fct>      <dbl>     <int> #> 1 Cluster_1  6356.         6 #> 2 Cluster_2 46659.         9 #> 3 Cluster_3  7256.         6 #> 4 Cluster_4  3617.         7 #> 5 Cluster_5   208.         4"}]
